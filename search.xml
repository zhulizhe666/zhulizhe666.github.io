<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Beautiful Soup:让爬虫变得更beautiful</title>
    <url>/2022/10/26/Beautiful-Soup-%E8%AE%A9%E7%88%AC%E8%99%AB%E5%8F%98%E5%BE%97%E6%9B%B4beautiful/</url>
    <content><![CDATA[<p>Beautiful Soup是一个可以从HTML或XML文件中提取数据的Python库，在熟练掌握后，它能帮你很轻松的实现文档中某一内容的查找定位。</p>
<span id="more"></span>
<h2 id="一-bs4模块的安装和Beautiful-Soup的引用"><a href="#一-bs4模块的安装和Beautiful-Soup的引用" class="headerlink" title="一.bs4模块的安装和Beautiful Soup的引用"></a>一.bs4模块的安装和Beautiful Soup的引用</h2><p>bs4模块不是系统自带的，个人喜欢用pip下载方便又快捷，打开电脑的命令行窗口，输入：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip <span class="keyword">install</span> bs4</span><br></pre></td></tr></table></figure>
<p>即可，在下载好bs4模块后，我们想调用里面的Beautful Soup，只需要在开头加上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure>
<p>注：BeautifulSoup不仅支持HTML解析器，还支持lxml,html5lib等第三方的解析器，但这些解析器需要另外下载，下表是<a href="https://beautifulsoup.cn/">BeautfulSoup中文文档</a>对其他一些解析器的介绍，本文之后的内容仅采用最基本的HTML解析器，其他的请大家自行上网查找资料，本文不做过多介绍：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">解析器</th>
<th style="text-align:left">使用方法</th>
<th style="text-align:left">优势</th>
<th style="text-align:left">劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Python标准库</td>
<td style="text-align:left"><code>BeautifulSoup(markup, &quot;html.parser&quot;)</code></td>
<td style="text-align:left">Python的内置标准库执行速度适中文档容错能力强</td>
<td style="text-align:left">Python 2.7.3 or 3.2.2)前 的版本中文档容错能力差</td>
</tr>
<tr>
<td style="text-align:left">lxml HTML 解析器</td>
<td style="text-align:left"><code>BeautifulSoup(markup, &quot;lxml&quot;)</code></td>
<td style="text-align:left">速度快文档容错能力强</td>
<td style="text-align:left">需要安装C语言库</td>
</tr>
<tr>
<td style="text-align:left">lxml XML 解析器</td>
<td style="text-align:left"><code>BeautifulSoup(markup, [&quot;lxml-xml&quot;])``BeautifulSoup(markup, &quot;xml&quot;)</code></td>
<td style="text-align:left">速度快唯一支持XML的解析器</td>
<td style="text-align:left">需要安装C语言库</td>
</tr>
<tr>
<td style="text-align:left">html5lib</td>
<td style="text-align:left"><code>BeautifulSoup(markup, &quot;html5lib&quot;)</code></td>
<td style="text-align:left">最好的容错性以浏览器的方式解析文档生成HTML5格式的文档</td>
<td style="text-align:left">速度慢不依赖外</td>
</tr>
</tbody>
</table>
</div>
<h2 id="二-BeautifulSoup的正确打开方式"><a href="#二-BeautifulSoup的正确打开方式" class="headerlink" title="二.BeautifulSoup的正确打开方式"></a>二.BeautifulSoup的正确打开方式</h2><p>我们既然都把BeautifulSoup从模块里单独引用出来了，说明其一定有着非常重要的作用，我们得到一段HTML文本，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>我们在用尽各种手段得到这段文本后，首先要对它进行解析：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page=BeautifulSoup(html_doc,<span class="string">&quot;html.parser&quot;</span>,from_encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>想要创建一个BeautifulSoup对象，需要三个参数，第一个是待解析的HTML文本，第二个是解析器类型，第三个是HTML文本的编码类型。它将HTNL文档转化为一棵标签树，所有的节点可分为以下几类</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>基本元素</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tag</td>
<td>标签，最基本的信息组织单位，分别用<>和</>标明开头和结尾</td>
</tr>
<tr>
<td>Name</td>
<td>标签的名字，<p>..</p>的名字是 p，格式：<tag>.name</tag></td>
</tr>
<tr>
<td>Attributes</td>
<td>标签的属性，字典形式组成，格式：<tag>.attrs</tag></td>
</tr>
<tr>
<td>NavigableString</td>
<td>标签内非属性字符串, <>...</>中字符串，格式：<tag>.string</tag></td>
</tr>
<tr>
<td>Comment</td>
<td>标签内字符串的注释部分，一种特殊的comment类型</td>
</tr>
</tbody>
</table>
</div>
<p>操作这棵标签树的最简单的办法是使用tag_name,用法<code>tag.tag_name</code>,例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page.head</span><br><span class="line"><span class="comment"># &#x27;&#x27;&#x27;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;&#x27;&#x27;&#x27;</span></span><br><span class="line">page.a</span><br><span class="line"><span class="comment"># &#x27;&#x27;&#x27;&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>但用此方法只能找到第一个标签，想要找到之后的标签以及全部的标签，就需要用到爬虫中很常用的BeautifulSoup类的两个函数。</p>
<h2 id="三-find和find-all"><a href="#三-find和find-all" class="headerlink" title="三.find和find_all"></a>三.find和find_all</h2><h3 id="一-find函数"><a href="#一-find函数" class="headerlink" title="(一) find函数"></a>(一) find函数</h3><p>find函数之返回第一个匹配的对象，基本语法为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">find(tag, attributes, recursive, text, keywords)</span><br></pre></td></tr></table></figure>
<p>我们在平常一般只用前2个参数：tag，attributes。</p>
<p><strong>tag</strong></p>
<p>需要搜素的标签名</p>
<p><strong>attributes</strong><br>属性参数 attributes 是用一个 Python <strong>字典</strong>封装一个标签的若干属性和对应的属性值。例如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page.find(<span class="string">&#x27;a&#x27;</span>,&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;link1&quot;</span>&#125;)返回</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>recursive</strong></p>
<p>递归参数recursive是一个布尔变量，如果recursive设置为True,调用该函数会从所有层级的标签中查找出符合要求的，而如果设置为False,就只会从一级标签中查找， recursive 默认值是 True ，一般不需要设置。</p>
<p><strong>text</strong><br>文本参数 text 有点不同，它是用标签的文本内容去匹配，而不是用标签的属性。</p>
<p><strong>keywords</strong><br>可以让你选择那些具有指定属性的标签，其实和用attributes传参基本一致</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#用keyword</span></span><br><span class="line">page.find(<span class="string">&#x27;a&#x27;</span>,<span class="built_in">id</span>=<span class="string">&quot;link1&quot;</span>)</span><br><span class="line"><span class="comment">#用attributes</span></span><br><span class="line">page.find(<span class="string">&#x27;a&#x27;</span>,&#123;<span class="string">&quot;id&quot;</span>:<span class="string">&quot;link1&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>在写属性名时，如果属性名和python的保留关键字相同，会出现报错的情况，如class,这时候我们有两种办法解决：</p>
<ul>
<li>在attrs属性用字典的方式进行参数传递</li>
<li>BeautifulSoup自带的特别关键字<strong>class_</strong></li>
</ul>
<h3 id="二-find-all函数"><a href="#二-find-all函数" class="headerlink" title="(二).find_all函数"></a>(二).find_all函数</h3><p>与find不同，find_all返回所有匹配到的结果,并将匹配结果打包成列表的形式返回。基本语法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">find_all(tag, attributes, recursive, text, limit, keywords)</span><br></pre></td></tr></table></figure>
<p>基本与find相同，只是多了一个limit参数</p>
<p><strong>limit</strong></p>
<p>范围限制参数 limit ，显然只用于 find_all 方法。 find 其实等价于 find_all 的 limit 等于1 时的情形。如果你只对网页中获取的前 x 项结果感兴趣，就可以设置它.</p>
<h2 id="四-获得你想要的值"><a href="#四-获得你想要的值" class="headerlink" title="四.获得你想要的值"></a>四.获得你想要的值</h2><p>我们在通过find和find_all方法找到了你想要找的标签后，该如何获得标签内你想要的某个属性值或者是文本呢？这里我们介绍两个方法get和get_text,例如我们定位到了标签<code>tag=&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code>,我们想要获取其href属性的地址，只需要</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tag.get(<span class="string">&quot;href&quot;</span>) <span class="comment">#参数为属性名</span></span><br></pre></td></tr></table></figure>
<p>如果我们需要的是标签的文本值Elsie，只需要</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tag.get_text（）</span><br></pre></td></tr></table></figure>
<p>怎么样是不是很简单呢？</p>
<p>关于BeautifulSoup我就介绍这么多啦，感谢各位观看！！</p>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/02/02/hello-world/</url>
    <content><![CDATA[<p>欢迎来到我的博客，在这里我会分享我的学习心得体会，偶尔也会分享一些其他内容，感谢各位支持ღ( ´･ᴗ･` )！！</p>
]]></content>
  </entry>
  <entry>
    <title>python requests库入门</title>
    <url>/2022/09/27/python-requests%E5%BA%93%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="Python-request库入门"><a href="#Python-request库入门" class="headerlink" title="Python request库入门"></a>Python request库入门</h1><h2 id="一-简介与安装"><a href="#一-简介与安装" class="headerlink" title="一.简介与安装"></a>一.简介与安装</h2><p>Requests 是⽤Python语⾔编写，基于urllib，采⽤Apache2 Licensed开源协议的 HTTP 库，该模块主要用来发送 HTTP 请求。</p>
<span id="more"></span>
<p>下载建议使用pip，用电脑打开命令行窗口，输入以下命令：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip <span class="keyword">install</span> requests</span><br></pre></td></tr></table></figure>
<p>库下载的慢的话可以换源，换源的方法如下：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">pip install +库名 -i +源</span><br><span class="line"><span class="symbol">eg:</span>    pip install requests -i <span class="symbol">http:</span>/<span class="regexp">/mirrors.aliyun.com/pypi</span><span class="regexp">/simple/</span></span><br></pre></td></tr></table></figure>
<p>几个国内源：</p>
<p>阿里云 <a href="https://links.jianshu.com/go?to=http%3A%2F%2Fmirrors.aliyun.com%2Fpypi%2Fsimple%2F">http://mirrors.aliyun.com/pypi/simple/</a><br>中国科技大学 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fpypi.mirrors.ustc.edu.cn%2Fsimple%2F">https://pypi.mirrors.ustc.edu.cn/simple/</a><br>豆瓣(douban) <a href="https://links.jianshu.com/go?to=http%3A%2F%2Fpypi.douban.com%2Fsimple%2F">http://pypi.douban.com/simple/</a><br>清华大学 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fpypi.tuna.tsinghua.edu.cn%2Fsimple%2F">https://pypi.tuna.tsinghua.edu.cn/simple/</a><br>中国科学技术大学 <a href="https://links.jianshu.com/go?to=http%3A%2F%2Fpypi.mirrors.ustc.edu.cn%2Fsimple%2F">http://pypi.mirrors.ustc.edu.cn/simple/</a></p>
<h2 id="二-使用"><a href="#二-使用" class="headerlink" title="二.使用"></a>二.使用</h2><p>关于获取网站数据，requests库提供了get和post两种方法，post是被设计用来向上放东西的，而get是被设计用来从服务器取东西的，如果你需要的数据在网页源代码中有，使用get；如果你需要的数据在网页源代码中没有，是从网络中获取的，那么选择post，下面以get为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;一次简单的爬虫尝试&quot;</span>) <span class="comment">#爬取百度信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests  <span class="comment">#导入requests库</span></span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://www.baidu.com&quot;</span> <span class="comment">#要爬取的网站地址</span></span><br><span class="line"></span><br><span class="line">resp=requests.get(url) <span class="comment">#用requests获取网站信息</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.text) <span class="comment">#打印信息</span></span><br></pre></td></tr></table></figure>
<p>打印结果：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">一次简单的爬虫尝试</span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--STATUS OK--&gt;</span><span class="tag">&lt;<span class="name">html</span>&gt;</span> <span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">content-type</span> <span class="attr">content</span>=<span class="string">text/html;charset</span>=<span class="string">utf-8</span>&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">X-UA-Compatible</span> <span class="attr">content</span>=<span class="string">IE</span>=<span class="string">Edge</span>&gt;</span><span class="tag">&lt;<span class="name">meta</span> <span class="attr">content</span>=<span class="string">always</span> <span class="attr">name</span>=<span class="string">referrer</span>&gt;</span><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">stylesheet</span> <span class="attr">type</span>=<span class="string">text/css</span> <span class="attr">href</span>=<span class="string">https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css</span>&gt;</span><span class="tag">&lt;<span class="name">title</span>&gt;</span>百度一下，你就知道<span class="tag">&lt;/<span class="name">title</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span> <span class="tag">&lt;<span class="name">body</span> <span class="attr">link</span>=<span class="string">#0000cc</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">wrapper</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">head</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">head_wrapper</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">s_form</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">s_form_wrapper</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">lg</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">hidefocus</span>=<span class="string">true</span> <span class="attr">src</span>=<span class="string">//www.baidu.com/img/bd_logo1.png</span> <span class="attr">width</span>=<span class="string">270</span> <span class="attr">height</span>=<span class="string">129</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">form</span> <span class="attr">id</span>=<span class="string">form</span> <span class="attr">name</span>=<span class="string">f</span> <span class="attr">action</span>=<span class="string">//www.baidu.com/s</span> <span class="attr">class</span>=<span class="string">fm</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">name</span>=<span class="string">bdorz_come</span> <span class="attr">value</span>=<span class="string">1</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">name</span>=<span class="string">ie</span> <span class="attr">value</span>=<span class="string">utf-8</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">name</span>=<span class="string">f</span> <span class="attr">value</span>=<span class="string">8</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">name</span>=<span class="string">rsv_bp</span> <span class="attr">value</span>=<span class="string">1</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">name</span>=<span class="string">rsv_idx</span> <span class="attr">value</span>=<span class="string">1</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">name</span>=<span class="string">tn</span> <span class="attr">value</span>=<span class="string">baidu</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;bg s_ipt_wr&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">kw</span> <span class="attr">name</span>=<span class="string">wd</span> <span class="attr">class</span>=<span class="string">s_ipt</span> <span class="attr">value</span> <span class="attr">maxlength</span>=<span class="string">255</span> <span class="attr">autocomplete</span>=<span class="string">off</span> <span class="attr">autofocus</span>=<span class="string">autofocus</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;bg s_btn_wr&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">id</span>=<span class="string">su</span> <span class="attr">value</span>=<span class="string">百度一下</span> <span class="attr">class</span>=<span class="string">&quot;bg s_btn&quot;</span> <span class="attr">autofocus</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span> <span class="tag">&lt;/<span class="name">form</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">u1</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://news.baidu.com</span> <span class="attr">name</span>=<span class="string">tj_trnews</span> <span class="attr">class</span>=<span class="string">mnav</span>&gt;</span>新闻<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">https://www.hao123.com</span> <span class="attr">name</span>=<span class="string">tj_trhao123</span> <span class="attr">class</span>=<span class="string">mnav</span>&gt;</span>hao123<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://map.baidu.com</span> <span class="attr">name</span>=<span class="string">tj_trmap</span> <span class="attr">class</span>=<span class="string">mnav</span>&gt;</span>地图<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://v.baidu.com</span> <span class="attr">name</span>=<span class="string">tj_trvideo</span> <span class="attr">class</span>=<span class="string">mnav</span>&gt;</span>视频<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://tieba.baidu.com</span> <span class="attr">name</span>=<span class="string">tj_trtieba</span> <span class="attr">class</span>=<span class="string">mnav</span>&gt;</span>贴吧<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">noscript</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl</span>=<span class="string">mn&amp;amp;u</span>=<span class="string">http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1</span> <span class="attr">name</span>=<span class="string">tj_login</span> <span class="attr">class</span>=<span class="string">lb</span>&gt;</span>登录<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;/<span class="name">noscript</span>&gt;</span> <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"><span class="variable language_">document</span>.<span class="title function_">write</span>(<span class="string">&#x27;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&#x27;</span>+ <span class="built_in">encodeURIComponent</span>(<span class="variable language_">window</span>.<span class="property">location</span>.<span class="property">href</span>+ (<span class="variable language_">window</span>.<span class="property">location</span>.<span class="property">search</span> === <span class="string">&quot;&quot;</span> ? <span class="string">&quot;?&quot;</span> : <span class="string">&quot;&amp;&quot;</span>)+ <span class="string">&quot;bdorz_come=1&quot;</span>)+ <span class="string">&#x27;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">                </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">//www.baidu.com/more/</span> <span class="attr">name</span>=<span class="string">tj_briicon</span> <span class="attr">class</span>=<span class="string">bri</span> <span class="attr">style</span>=<span class="string">&quot;display: block;&quot;</span>&gt;</span>更多产品<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">ftCon</span>&gt;</span> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">ftConw</span>&gt;</span> <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">lh</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://home.baidu.com</span>&gt;</span>关于百度<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://ir.baidu.com</span>&gt;</span>About Baidu<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;/<span class="name">p</span>&gt;</span> <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">cp</span>&gt;</span><span class="symbol">&amp;copy;</span>2017<span class="symbol">&amp;nbsp;</span>Baidu<span class="symbol">&amp;nbsp;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://www.baidu.com/duty/</span>&gt;</span>使用百度前必读<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="symbol">&amp;nbsp;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">http://jianyi.baidu.com/</span> <span class="attr">class</span>=<span class="string">cp-feedback</span>&gt;</span>意见反馈<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="symbol">&amp;nbsp;</span>京ICP证030173号<span class="symbol">&amp;nbsp;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">//www.baidu.com/img/gs.gif</span>&gt;</span> <span class="tag">&lt;/<span class="name">p</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;/<span class="name">div</span>&gt;</span> <span class="tag">&lt;/<span class="name">body</span>&gt;</span> <span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们发现打印出来的内容很复杂看不懂，没有关系，因为这是HTML（超文本语言）,我们之后会简单介绍，现在回到程序自身，</p>
<p>get函数有几个参数：</p>
<p>1.url:即我们请求的网站的网址，是必要参数，填在第一位；</p>
<p>2.headers:可选参数，请求头文件，输入要求字典形式，有时我们在打印网页源代码时，没有报错，但打印不出信息，可能就是User-Agent的问题，这时就需要添加一个带User-Agent的headers文件；</p>
<p>3.params:可选参数，请求参数，输入要求字典形式，如在搜索时设置kw=小狗；</p>
<p>4.verify：可选参数，ssl证书验证，输入是bool类型，有时候在访问网站时会报SSLError,这时候我们就可以通过设置verify参数值为false,在请求是不验证网站的ca证书，设置完以后运行时可能会出现warning，如果看着不顺眼，可以加上</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib3</span><br><span class="line">urllib3.disable_warnings() </span><br></pre></td></tr></table></figure>
<p>去掉警告；</p>
<p>5.timeout:可选参数，get再申请访问时，所用时间如果超过timeout设置的值，就会返回timeoutError；</p>
<p>6.proxies:可选参数，有时候因为一些原因，你的IP地址可能会被网站封了，禁止你访问，这时我们就需要用该参数，使用代理IP访问网站；</p>
<p>在用get申请访问时，有时会因为网络不良或连接不好无法请求到网站,遇到这种情况可以在get前加上<code>requests.adapters.DEFAULT_RETRIES = 5</code></p>
<p>设置如果连接不上重新连接的次数，可以搭配get的timeout参数 使用，设置例如30s连接不上重新连接。</p>
<p>使用requests方法后，会返回一个response对象，其存储了服务器响应的内容，在输出resp响应时，如果选择直接输出，输出的是状态码：如果输出<Response [200]>，则说明连接网站成功，如果输出<Response [400]>，则说明没有连接上。</Response></Response></p>
<p>在输出resp时，也可以选择输出resp.text，输出响应的内容，也就是申请访问的网页的源代码，有时我们在输出的时候得到的结果中会有很多看不懂的字符，那是因为windows系统默认的字符集是GBK，而网页源代码所使用的字符集并不一定是GBK，例如在上面的输出中我们发现在第二行有一个 <code>charset=utf-8</code> ，说明百度网页源代码使用的字符集是utf-8，这时我们只要在输出之前设置<code>resp.encoding=&quot;utf-8&quot;</code>即可正确输出源代码内容。</p>
<h2 id="三-第一次反爬"><a href="#三-第一次反爬" class="headerlink" title="三.第一次反爬"></a>三.第一次反爬</h2><p>我们用电脑浏览器登录www.baidu.com，鼠标右键查看网页源代码，发现看到的源代码很长很长，和我们之前获得的根本不一样，</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">百度网页实际源代码部分截取</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;head&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;s_top_wrap&quot;</span> <span class="attr">class</span>=<span class="string">&quot;s-top-wrap s-isindex-wrap &quot;</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;s-top-nav&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;s-center-box&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;u&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;toindex&quot;</span> <span class="attr">href</span>=<span class="string">&quot;/&quot;</span>&gt;</span>百度首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;javascript:;&quot;</span> <span class="attr">name</span>=<span class="string">&quot;tj_settingicon&quot;</span> <span class="attr">class</span>=<span class="string">&quot;pf&quot;</span>&gt;</span>设置<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;c-icon c-icon-triangle-down&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://passport.baidu.com/v2/?login&amp;tpl=mn&amp;u=http%3A%2F%2Fwww.baidu.com%2F&amp;sms=5&quot;</span> <span class="attr">name</span>=<span class="string">&quot;tj_login&quot;</span> <span class="attr">class</span>=<span class="string">&quot;lb&quot;</span> <span class="attr">onclick</span>=<span class="string">&quot;return false;&quot;</span>&gt;</span>登录<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bdpfmenu&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;s-top-left&quot;</span> <span class="attr">class</span>=<span class="string">&quot;s-top-left-new s-isindex-wrap&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://news.baidu.com&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span> <span class="attr">class</span>=<span class="string">&quot;mnav c-font-normal c-color-t&quot;</span>&gt;</span>新闻<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.hao123.com?</span></span></span><br></pre></td></tr></table></figure>
<p>而且仔细观察之前获得的数据，发现一些网页上有的元素其中没有，例如百度热搜，说明我们被反爬了，百度网站没有让我们获取我们想要的信息，其实解决的办法很简单，就是利用之前说过的get函数的可选参数headers,鼠标右击百度网页检查-network，刷新网页，随便点开一个文件点开headers，拉到最下方request headers，我们会找到一个user-agent，我们把它复制下来，设置为headers作为参数发给网站：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp=requests.get(url,headers=headers)</span><br></pre></td></tr></table></figure>
<p>​    这之后再打印网站信息，就会发现和在浏览器中打开的一样啦。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫之re模块</title>
    <url>/2022/10/06/python%E7%88%AC%E8%99%AB%E4%B9%8Bre%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h2 id="python爬虫之re模块"><a href="#python爬虫之re模块" class="headerlink" title="python爬虫之re模块"></a>python爬虫之re模块</h2><p>本文介绍如何通过python的re模块对网页文本进行解析，获得你想要的内容。</p>
<span id="more"></span>
<h2 id="一-正则表达式"><a href="#一-正则表达式" class="headerlink" title="一.正则表达式"></a>一.正则表达式</h2><h3 id="（一）定义"><a href="#（一）定义" class="headerlink" title="（一）定义"></a>（一）定义</h3><p><strong>正则表达式</strong>，又称规则表达式<strong>,</strong>（Regular Expression，在代码中常简写为regex、regexp或RE），是一种文本模式，可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。</p>
<h3 id="（二）语法"><a href="#（二）语法" class="headerlink" title="（二）语法"></a>（二）语法</h3><p>在线正则表达式测试网站：<a href="https://c.runoob.com/front-end/854/">https://c.runoob.com/front-end/854/</a></p>
<p>​                                              <a href="https://tool.oschina.net/regex/">https://tool.oschina.net/regex/</a></p>
<p>我们简单列出一些正则表达式的语法</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>字符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>[ABC]</td>
<td>匹配[…]中的所有字符，如[aeiou]匹配所有的元音字母；</td>
</tr>
<tr>
<td><sup><a href="#fn_ABC" id="reffn_ABC">ABC</a></sup></td>
<td>匹配除[…]中字符的所有字符；</td>
</tr>
<tr>
<td>[A-Z]</td>
<td>[A-Z]表示一个区间，比配所有大写字母，[a-z]表示所有小写字母</td>
</tr>
<tr>
<td>.</td>
<td>比配除换行符之外的任何单个字符</td>
</tr>
</tbody>
</table>
</div>
<p>更多具体的可参考<a href="https://www.runoob.com/regexp/regexp-syntax.html">https://www.runoob.com/regexp/regexp-syntax.html</a></p>
<p>在爬虫中，我们使用最多的是一种”贪婪匹配”：<strong>.*</strong>和<strong>.*?</strong>。</p>
<p>1.<strong>*</strong>和<strong>+</strong>限定符是贪婪的，会尽可能多的匹配字符，例如<strong>&lt;.*&gt;</strong>会匹配文本中从第一个&lt;到最后一个&gt;中包括的所有内容，如用<strong>&lt;.*&gt;</strong>匹配<code>&lt;h1&gt;zhulizhe&lt;h1&gt;</code>的结果就是<code>&lt;h1 &gt;zhulizhe&lt;h1&gt;</code>。</p>
<p>2.我们通过在<strong>*</strong>，<strong>+</strong>后面加上？,可以使该表达式从”贪婪”表达式转换为”非贪婪”表达式或者最小匹配。例如<strong>&lt;.*？&gt;</strong>匹配所有最小的&lt;&gt;中的内容，如用<strong>&lt;.*？&gt;</strong>匹配<code>&lt;h1&gt;zhulizhe&lt;h2&gt;</code>结果有两个：<code>&lt;h1&gt;和&lt;h2&gt;</code>。</p>
<p>通过各种语法的组合正则表达式还能进行很多有意思的匹配，但在这里就不过多介绍了。</p>
<h2 id="二-re模块"><a href="#二-re模块" class="headerlink" title="二.re模块"></a>二.re模块</h2><p>re模块是python独有的利用正则表达式<strong>匹配字符串的模块</strong>,re模块是一个自带的第三方库，并不需要你额外下载，只需要在开头加上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure>
<p>调用即可。</p>
<p>本文对re模块不做过多介绍，着重介绍爬虫最常用的<strong>re.complie</strong>函数</p>
<p><strong>re.comple</strong>函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，语法格式是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">re.<span class="built_in">compile</span>(pattern[,flags])</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>pattern : 一个字符串形式的正则表达式</li>
<li>flags 可选，表示匹配模式,常见的有：</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">修饰符</th>
<th style="text-align:left">描　　述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>re.I</code></td>
<td style="text-align:left">使匹配对大小写不敏感</td>
</tr>
<tr>
<td style="text-align:left"><code>re.L</code></td>
<td style="text-align:left">做本地化识别（locale-aware）匹配</td>
</tr>
<tr>
<td style="text-align:left"><code>re.M</code></td>
<td style="text-align:left">多行匹配，影响 <code>^</code> 和 <code>$</code></td>
</tr>
<tr>
<td style="text-align:left"><code>re.S</code></td>
<td style="text-align:left">使。匹配包括换行符在内的所有字符</td>
</tr>
<tr>
<td style="text-align:left"><code>re.U</code></td>
<td style="text-align:left">根据 Unicode 字符集解析字符。这个标志影响 <code>\w</code>、<code>\W</code>、<code>\b</code> 和 <code>\B</code></td>
</tr>
<tr>
<td style="text-align:left"><code>re.X</code></td>
<td style="text-align:left">该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解</td>
</tr>
</tbody>
</table>
</div>
<p>我们通常选择模式为re.S，为了防止字符串中的转义字符，我们通常使用r”………”的形式，这个r代表了原字符串的意思，可以省略转义字符。</p>
<p><strong>特殊的，我们在patten中通常还会使用解析结构式 (?P<groupname>匹配规则) 其中 ?P<groupname> 来定义一个组，并且每一个分组用()包起了，表示一个分组如（?P<name>），组名后面跟一个正则匹配公式，匹配值可以通过group(“groupname”)获取。</name></groupname></groupname></strong></p>
<p>下面我们正式在python爬虫中试用一下compile函数。</p>
<h2 id="三-re爬虫实战"><a href="#三-re爬虫实战" class="headerlink" title="三.re爬虫实战"></a>三.re爬虫实战</h2><p><img src="/2022/10/06/python%E7%88%AC%E8%99%AB%E4%B9%8Bre%E6%A8%A1%E5%9D%97/image-20221006231650163.png" alt="image-20221006231650163"></p>
<p>我们想要获取百度主页的百度热搜信息，右键查看网页源代码，Crtl+F搜索<strong>卫星视角下的祖国大地有多美</strong></p>
<p><img src="/2022/10/06/python%E7%88%AC%E8%99%AB%E4%B9%8Bre%E6%A8%A1%E5%9D%97/image-20221006231620796.png" alt="image-20221006231620796"></p>
<p>发现有两处，且其他的热搜内容也都在，我们任选一处就行获取就行。我们观察一下这几处热搜内容的特征，发现内容的前面都有<strong>“title-content-title”&gt;</strong>，后面都有<strong>&lt;/span&gt;</strong>且搜索后有且仅有这几处有，我们就可以通过它来定位,匹配的代码就可以这样写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj=re.<span class="built_in">compile</span>(<span class="string">r&quot;\&quot;title-content-title\&quot;&gt;(?P&lt;resou&gt;.*?)&lt;/span&gt;&quot;</span>,re.S) <span class="comment">#\表示转义&quot;</span></span><br></pre></td></tr></table></figure>
<p>在这里我们在介绍re的两个函数findall和finditer，findall将匹配到的所有内容打包成列表的形式返回而finditer则返回一个迭代器。我们在这里选择使用finditer函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=obj.findall(page_content)</span><br></pre></td></tr></table></figure>
<p>如果想要遍历迭代器并打印内容可以这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> result:</span><br><span class="line">    <span class="built_in">print</span>(it.group(<span class="string">&quot;resou&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>打印结果为：</p>
<p><img src="/2022/10/06/python%E7%88%AC%E8%99%AB%E4%B9%8Bre%E6%A8%A1%E5%9D%97/image-20221006231445783.png" alt="image-20221006231445783"></p>
<p>下面附上<strong>完整代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests  <span class="comment">#导入requests库</span></span><br><span class="line"><span class="keyword">import</span> re <span class="comment">#导入re库</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;通过re正则表达式解析文本&quot;</span>)</span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://www.baidu.com/&quot;</span>  <span class="comment">#要爬取的网站地址</span></span><br><span class="line"></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;  <span class="comment">#文件头防反爬</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">resp=requests.get(url,headers=headers)  <span class="comment">#调用用requests获取网站信息</span></span><br><span class="line"></span><br><span class="line">resp.encoding=<span class="string">&quot;utf-8&quot;</span>  <span class="comment">#修改解码格式</span></span><br><span class="line"></span><br><span class="line">page_content=resp.text</span><br><span class="line"></span><br><span class="line">obj=re.<span class="built_in">compile</span>(<span class="string">r&quot;\&quot;title-content-title\&quot;&gt;(?P&lt;resou&gt;.*?)&lt;/span&gt;&quot;</span>,re.S)  <span class="comment">#正则表达式的解析规则</span></span><br><span class="line"></span><br><span class="line">result=obj.finditer(page_content)  <span class="comment">##匹配文本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> result:  </span><br><span class="line">    <span class="built_in">print</span>(it.group(<span class="string">&quot;resou&quot;</span>))  <span class="comment">##输出，不要忘了用.group(&quot;groupname&quot;)获取值</span></span><br></pre></td></tr></table></figure>
<p>本文到此就结束了，感谢支持ღ( ´･ᴗ･` )。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫入门</title>
    <url>/2022/09/26/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="python爬虫入门"><a href="#python爬虫入门" class="headerlink" title="python爬虫入门"></a>python爬虫入门</h1><h2 id="一-什么是爬虫"><a href="#一-什么是爬虫" class="headerlink" title="一.什么是爬虫"></a>一.什么是爬虫</h2><p>网络爬虫（Crawler）又称网络蜘蛛，或者网络机器人（Robots）。它是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。爬虫通过程序模拟用户访问网页的过程，解析网页源代码或通过抓包获取网页上所含的文字，图片，视频等资源，并将其保存下来。</p>
<span id="more"></span>
<h2 id="二-为什么使用爬虫"><a href="#二-为什么使用爬虫" class="headerlink" title="二.为什么使用爬虫"></a>二.为什么使用爬虫</h2><p>爬虫可以高效的批量的获取网页上的信息，创建或维护网页的人一般为了方便与统一，例如网页小说的第一页和第二页，网页源代码中紧紧改变了某几个属性的值，如content，整体源代码的框架并没有改变，因此，我们只要通过分析某一页网页的源代码，并学会如何从其获取信息，那么我们也就等于学会了如何从这一种网页中获取信息，即可通过程序批量获得此种网页上我们所需要的信息。而不用再和之前一样自己去一页一页下载，是真正意义上的一劳永逸。</p>
<h2 id="三-为什么用python"><a href="#三-为什么用python" class="headerlink" title="三.为什么用python"></a>三.为什么用python</h2><p>学过python的人都知道，python语法简单，且有非常丰富的第三方库，世界各地的大佬们帮我们把各种函数，类写好封装在库中，我们所需要做的仅仅是学会如何去使用他们。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>小规模，数量小，爬去速度不敏感，requests库</th>
<th>中规模，数据规模较大，爬取速度敏感scrapy库</th>
<th>大规模，搜索引擎,爬取速度关键定制开发</th>
</tr>
</thead>
<tbody>
<tr>
<td>爬取网页 玩转网页</td>
<td>爬取网站 爬取系列网站</td>
<td>爬取全网</td>
</tr>
</tbody>
</table>
</div>
<h2 id="四-一些其他关于爬虫的"><a href="#四-一些其他关于爬虫的" class="headerlink" title="四.一些其他关于爬虫的"></a>四.一些其他关于爬虫的</h2><h3 id="（一）Robots协议"><a href="#（一）Robots协议" class="headerlink" title="（一）Robots协议"></a>（一）Robots协议</h3><p>网站在反爬方面一般有两种措施，第一种是通过反爬技术手段，例如登录输入验证码，机器人验证等方式，判断你是程序还是真人访问网页以进行反爬，第二种就是通过Robots协议。</p>
<p>Robots协议（也称为爬虫协议、机器人协议等），全称是“网络爬虫排除标准”，一般我们再网站主页面网址后加上/robots.txt即可查看网站的Robots协议（如果没有则说明网站允许对数据进行爬取），Robots协议规定了网站那些内容允许和不允许爬取，允许和不允许某些爬虫爬取等信息，例如淘宝网的Robots协议：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">User-agent</span><span class="punctuation">: </span>Baiduspider</span><br><span class="line"><span class="attribute">Disallow</span><span class="punctuation">: </span>/</span><br><span class="line"></span><br><span class="line"><span class="attribute">User-agent</span><span class="punctuation">: </span>baiduspider</span><br><span class="line"><span class="attribute">Disallow</span><span class="punctuation">: </span>/</span><br></pre></td></tr></table></figure>
<p>说明淘宝网不希望百度的爬虫爬取其信息。</p>
<p>Robots协议是建议但非约束性，简单地来说就是一份君子协议（防君子不防小人），但如果你违反Robots协议，可能会面临一定的法律风险。以下是对是否遵守Robots协议的建议：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>访问量小:可以遵守 访问量较大：建议遵守</th>
<th>非商业且偶尔:建议遵守 商业利益:必须遵守</th>
<th>必须遵守</th>
</tr>
</thead>
<tbody>
<tr>
<td>爬取网页 玩转网页</td>
<td>爬取网站 爬取系列网站</td>
<td>爬取全网</td>
</tr>
</tbody>
</table>
</div>
<h3 id="（二）学习爬虫的资源"><a href="#（二）学习爬虫的资源" class="headerlink" title="（二）学习爬虫的资源"></a>（二）学习爬虫的资源</h3><p>1.<a href="https://cuiqingcai.com/17777.html">https://cuiqingcai.com/17777.html</a>    崔庆才大佬的博客，写的很详细，另外大佬写的书也很不错；</p>
<p>2.<a href="http://c.biancheng.net/python_spider/">http://c.biancheng.net/python_spider/</a>     网站名虽然叫C语言编程网，但里面也有其他语言的教程，很不错的一个网站；</p>
<p>3.<a href="http://www.glidedsky.com/">http://www.glidedsky.com/</a>    新手可以练习爬虫的地方，需要注册登陆，进去后可以向闯关一样完成挑战；</p>
<p>4.哔哩哔哩，知乎，CSDN等等较为常见的网站，现在网上关于爬虫的教程越来越多，注意甄别好坏，选择适合自己的。</p>
<p>在接下来的文章中我们正式开始python爬虫的学习。</p>
<h2 id="五-注"><a href="#五-注" class="headerlink" title="五.注"></a>五.注</h2><p>这是我在我博客上发的第一篇文章，博客早就搭好了，但比较懒一直没写文章，最近有空而且刚好自学了python爬虫，就发几篇博客也当做自己的复习，今后可能还会发一些ACM等别的方面的内容，作者语文学的不太好，博客可能写的有点烂见谅。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>一文搞懂导航电文</title>
    <url>/2022/10/04/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%AF%BC%E8%88%AA%E7%94%B5%E6%96%87-1/</url>
    <content><![CDATA[<h1 id="一文搞懂导航电文（以Rinex3-04为例）"><a href="#一文搞懂导航电文（以Rinex3-04为例）" class="headerlink" title="一文搞懂导航电文（以Rinex3.04为例）"></a>一文搞懂导航电文（以Rinex3.04为例）</h1><h2 id="一-什么是Rinex"><a href="#一-什么是Rinex" class="headerlink" title="一.什么是Rinex"></a>一.什么是Rinex</h2><span id="more"></span>
<p>RINEX（Receiver Independent Exchange Format/与接收机无关的交换格式）是一种在GPS测量应用中普遍采用的标准数据格式。该格式采用文本文件存储数据，数据记录格式与接收机的制造厂商和具体型号无关。</p>
<h2 id="二-Rinex格式文件的下载方式"><a href="#二-Rinex格式文件的下载方式" class="headerlink" title="二.Rinex格式文件的下载方式"></a>二.Rinex格式文件的下载方式</h2><p>附上网址：<br>1.<a href="https://link.zhihu.com/?target=ftp%3A//nfs.kasi.re.kr/">ftp://nfs.kasi.re.kr/</a>    与igs内容差不多，部分会缺，在电脑文件管理器中打开即可；</p>
<p>2.<a href="http://www.csno-tarc.cn/datacenter/ephemeris">http://www.csno-tarc.cn/datacenter/ephemeris</a>    选择广播星历下载即可，可选择日期，打开链接的方式同上；</p>
<p>3.cddss官网下载(不建议)，需注册，下载比较繁琐；</p>
<p>(注：美国出于信息安全的考虑，关闭了所有通过ftp下载igs,cddss上的数据的途径，网上搜索下载Rinex格式文件的网站是会看到很多ftp链接里带有igs,cddss的，作者试过全都打不开)</p>
<p>4.<a href="https://igs.org/formats-and-standards/">https://igs.org/formats-and-standards/</a>    下载Rinex各版本格式说明文件，根据需要下载即可。</p>
<h2 id="三-Rinex导航电文内容说明"><a href="#三-Rinex导航电文内容说明" class="headerlink" title="三.Rinex导航电文内容说明"></a>三.Rinex导航电文内容说明</h2><p>Rinex格式的导航电文分为文件头和数据两部分，我们分别进行介绍：</p>
<h3 id="（一）文件头"><a href="#（一）文件头" class="headerlink" title="（一）文件头"></a>（一）文件头</h3><p>我们先看看Rinex3.04版本的说明文档中对文件头格式的说明：</p>
<p><img src="/2022/10/04/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%AF%BC%E8%88%AA%E7%94%B5%E6%96%87-1/image-20220930132004228.png" alt="image-20220930132004228"></p>
<p>我们发现图表的最后一列有一列FORMAT,这里的FORMAT指<strong>【FORTRAN 95/2003标准中的读写格式定义】</strong></p>
<p>具体有：</p>
<ul>
<li>An: 表示以n个字符宽度输出字符串</li>
<li>Fn.m: 表示以n个字符宽输出浮点数，小数点后占m个字符宽度</li>
<li>In[.m]: 表示以n个字符宽输出整数，至少输出m位数字（不足以“0”补齐），方括号表示可选，In表示输出占n个字符宽的整数，即n位整数，不足也不需以“0”补齐</li>
<li>nX: 表示向右跳过n个字符的宽度</li>
<li>Tn: 表示输出位置移动到本行第n列</li>
</ul>
<p>例如F9.2.11X就指表示以9个字符宽输出浮点数，小数点后占2个字符宽度，且向右跳过11个字符的宽度.</p>
<p>在了解了格式之后我们给出一个Rinex格式的文件的文件头结合上图介绍：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line">     <span class="attribute">3</span>.<span class="number">04</span>           N: GNSS NAV DATA    M: MIXED            RINEX VERSION / TYPE</span><br><span class="line"><span class="attribute">ssrcrin</span>-<span class="number">13</span>.<span class="number">7</span>.<span class="number">0</span>x                         <span class="number">20220101</span> <span class="number">000000</span> UTC PGM / RUN BY / DATE </span><br><span class="line">                                                            <span class="attribute">END</span> OF HEADER       </span><br></pre></td></tr></table></figure>
<p>先看第一行，<strong>“RINEX VERSION / TYPE”</strong>说明第一行写的是Rinex格式的版本和该文件的类型，”3.04”<strong>说明该文件是</strong>3.04版本的，我们想要读懂它就需要看Rinex304的说明文档，<strong>“N: GNSS NAV DATA”</strong>说明这是文件存的是导航电文数据，<strong>“M: MIXED”</strong>说明该文档存有多个导航系统的数据；</p>
<p>第二行<strong>“PGM / RUN BY / DATE”</strong>给出了创建当前文件的程序的名称是ssrcrin-13.7.0x，没有写创建当前文件的机构的名称，创建当前文件的时间是20220101 000000，格式是”yyyymmdd hhmmss”,采用的时间是”UTC”时间，即协调世界时；</p>
<p>第三行<strong>“END OF HEADER”</strong>说明文件头结束。</p>
<h3 id="（二）数据"><a href="#（二）数据" class="headerlink" title="（二）数据"></a>（二）数据</h3><p>下图是Rinex3.04版本的说明文档中对数据格式的说明：</p>
<p><img src="/2022/10/04/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%AF%BC%E8%88%AA%E7%94%B5%E6%96%87-1/image-20220930140604755.png" alt="image-20220930140604755"></p>
<p>我们结合一颗GPS卫星的数据进行分析：</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">G24 2022 01 01 02 00 00 2.766801044345E<span class="string">-04</span> 7.958078640513E<span class="string">-13</span> 0.000000000000E<span class="string">+00</span></span><br><span class="line">     7.200000000000E<span class="string">+01</span><span class="string">-5</span>.281250000000E<span class="string">+00</span> 5.369152218170E<span class="string">-09</span> 7.382124868389E<span class="string">-01</span></span><br><span class="line">    <span class="string">-3</span>.110617399216E<span class="string">-07</span> 1.224164501764E<span class="string">-02</span> 7.973983883858E<span class="string">-06</span> 5.153692775726E<span class="string">+03</span></span><br><span class="line">     5.256000000000E<span class="string">+05</span><span class="string">-8</span>.381903171539E<span class="string">-08</span> 2.017266027501E<span class="string">+00</span> 1.136213541031E<span class="string">-07</span></span><br><span class="line">     9.341236686746E<span class="string">-01</span> 2.133437500000E<span class="string">+02</span> 7.961493677997E<span class="string">-01</span><span class="string">-8</span>.411778955786E<span class="string">-09</span></span><br><span class="line">    <span class="string">-7</span>.186013612025E<span class="string">-10</span> 1.000000000000E<span class="string">+00</span> 2.190000000000E<span class="string">+03</span> 0.000000000000E<span class="string">+00</span></span><br><span class="line">     2.000000000000E<span class="string">+00</span> 0.000000000000E<span class="string">+00</span> 2.328306436539E<span class="string">-09</span> 7.200000000000E<span class="string">+01</span></span><br><span class="line">     5.184180000000E<span class="string">+05</span> 4.000000000000E<span class="string">+00</span></span><br></pre></td></tr></table></figure>
<p>解算卫星在WGS-84坐标系的坐标的参数有：</p>
<script type="math/tex; mode=display">
t_{oe}  星历参考时间</script><script type="math/tex; mode=display">
\sqrt{A}卫星轨道半长轴A的平方根</script><script type="math/tex; mode=display">
e卫星轨道偏心率</script><script type="math/tex; mode=display">
i_0轨道倾角</script><script type="math/tex; mode=display">
\varOmega _0周内时为0时的轨道升交点赤经</script><script type="math/tex; mode=display">
\omega近地点角距</script><script type="math/tex; mode=display">
M_0平近点角</script><script type="math/tex; mode=display">
\varDelta _n卫星平均角速度校正值</script><script type="math/tex; mode=display">
\dot{i}轨道倾角的变化率</script><script type="math/tex; mode=display">
\varOmega轨道升交点赤经的变化率</script><script type="math/tex; mode=display">
C_{uc}升交点角距余弦调和校正振幅</script><script type="math/tex; mode=display">
C_{us}升交点角距正弦调和校正振幅</script><script type="math/tex; mode=display">
C_{rc}轨道半径余弦调和校正振幅</script><script type="math/tex; mode=display">
C_{rs}轨道半径正弦调和校正振幅</script><script type="math/tex; mode=display">
C_{ic}轨道倾角余弦调和校正振幅</script><script type="math/tex; mode=display">
C_{is}轨道倾角正弦调和校正振幅</script><p>G24是卫星编号,后面4个数据分别是Toc、卫星钟差、卫星钟漂、卫星钟漂变化率,第二行是第二行4个数据分别是IODE、Crs、Δ n和M0，并在后面标好了单位，如Crs的单位是(meters)米，M0的单位是(radians)弧度。之后各行的数据对照官方文档一一对应即可。</p>
<h2 id="四-总结"><a href="#四-总结" class="headerlink" title="四.总结"></a>四.总结</h2><p>导航电文不难看懂，难的是耐下心来对照官方说明文档搞懂各行各个数据的意义，在读懂了导航电文的含义后，接下来的步骤就是解算卫星在WGS-84坐标系下的的坐标，我会在之后的文章中介绍。本文章仅代表个人观点和看法，难免会有错误和疏漏，如有错误希望大家可以和我指出ღ( ´･ᴗ･` )。</p>
<h2 id="五-计算程序"><a href="#五-计算程序" class="headerlink" title="五.计算程序"></a>五.计算程序</h2><p>计算部分按公式一步步推就行了，作者很懒，详细的步骤就不给出了，值得一提的是树上给的公式和常量很多是错的，所以建议根据PPT上的公式进行程序的编写，需要详细步骤的我推荐一下这篇文章：<a href="https://blog.csdn.net/tyst08/article/details/102462810，公式都是正确的，写的很详细很不错，可以一步步跟进编写。">https://blog.csdn.net/tyst08/article/details/102462810，公式都是正确的，写的很详细很不错，可以一步步跟进编写。</a></p>
]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Rinex</tag>
        <tag>卫星导航</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫的好帮手——web自动化</title>
    <url>/2022/10/21/%E7%88%AC%E8%99%AB%E7%9A%84%E5%A5%BD%E5%B8%AE%E6%89%8B%E2%80%94%E2%80%94web%E8%87%AA%E5%8A%A8%E5%8C%96/</url>
    <content><![CDATA[<p>网课没事开个新坑，爬虫还是会更新的。</p>
<span id="more"></span>
<h2 id="一-为什么用web自动化"><a href="#一-为什么用web自动化" class="headerlink" title="一.为什么用web自动化"></a>一.为什么用web自动化</h2><p>相信很多人在进行爬虫时都有这样的问题，你在进行爬虫时并不能看到爬虫对网页的那些部分，那些内容进行了操作，不像自己平时上网的时候，自己亲手一步一步操作，一个网页一个网页打开，亲眼看着网页操作有一种实在感。可以选择自己想要的内容浏览下载，而爬虫显然做不到这一点，因为它是不可视的，这时候，我们就需要他的好兄弟web自动化登场了。</p>
<h2 id="二-什么是web自动化"><a href="#二-什么是web自动化" class="headerlink" title="二.什么是web自动化"></a>二.什么是web自动化</h2><p>顾名思义，web自动化就是利用程序和浏览器驱动，实现电脑控制浏览器访问页面，获取你想要的信息，其优势在于利用浏览器驱动，使程序的操作可以在浏览器界面上一步一步进行，就和人工的一样，但其速度又远远快于人工，还能实现许多人工做不到的功能，同时web自动化也是反爬的好帮手，因为很多网页选择用CSS渲染，不直接将页面元素放入源代码中而使用web自动化就没有这个问题。</p>
<h2 id="三-从selenium到splinter"><a href="#三-从selenium到splinter" class="headerlink" title="三.从selenium到splinter"></a>三.从selenium到splinter</h2><p>提到web自动化，不得不提python的selenium模块，selenium是最广泛使用的开源Web UI（用户界面）自动化测试套件之一，Selenium支持的语言包括C#,JAVA,Pert,PHP,python,ruby,目前，selenium web驱动程序最受python、c#欢迎。Selenium测试脚本可以使用任何支持的编程语言进行编码，并且可以直接再大多数现代Web浏览器中运行。在爬虫领域，selenium同样是一把利器，能够解决大部分的网页反爬问题。python中还有别人做过web自动化的尝试，但是都不如selenium做的好，而这其中splinter对selenium进行了二次封装，是一个相对做的比较不错的模块，splinter在以后的文章可能会介绍。</p>
<h2 id="四-selenium的安装及使用"><a href="#四-selenium的安装及使用" class="headerlink" title="四.selenium的安装及使用"></a>四.selenium的安装及使用</h2><p>安装不用我再多说，直接简简单单<code>pip install selenium</code>,使用的话，要想通过程序调用浏览器，还要下载你选用的浏览器对应的浏览器驱动。下面给出一些常用浏览器的驱动下载地址：</p>
<p>Chrome浏览器  <a href="https://chromedriver.storage.googleapis.com/index.html">https://chromedriver.storage.googleapis.com/index.html</a></p>
<p>Firefox浏览器  <a href="https://github.com/mozilla/geckodriver/releases">https://github.com/mozilla/geckodriver/releases</a></p>
<p>Edge浏览器  <a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/、">https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/、</a></p>
<p>注意下载的浏览器驱动一定要和你的浏览器版本号对应，我们下面以Chrome浏览器为例：</p>
<p>打开设置，点击关于Chrome，查看版本号</p>
<p><img src="/2022/10/21/%E7%88%AC%E8%99%AB%E7%9A%84%E5%A5%BD%E5%B8%AE%E6%89%8B%E2%80%94%E2%80%94web%E8%87%AA%E5%8A%A8%E5%8C%96/image-20221021084151498.png" alt="image-20221021084151498"></p>
<p>我的Chrome是105.0.5195版本的，那么我们的浏览器驱动也要下载相应的版本</p>
<p><img src="/2022/10/21/%E7%88%AC%E8%99%AB%E7%9A%84%E5%A5%BD%E5%B8%AE%E6%89%8B%E2%80%94%E2%80%94web%E8%87%AA%E5%8A%A8%E5%8C%96/image-20221021084720887.png" alt="image-20221021084720887"></p>
<p>任选一个下载即可。</p>
<p>下砸好了后要怎么使用浏览器驱动呢？这里我给出两种方法：</p>
<p>1.在程序中写明调用的浏览器驱动的路径，这个在下一节我们会具体介绍；</p>
<p>2.将驱动文件放到和浏览器同一个路径中，并将路径添加到环境变量，添加环境变量的方法这里我就不再多说了。</p>
<h1 id="本次的内容就到这里了，下一次我们继续selenium模块的介绍与使用。"><a href="#本次的内容就到这里了，下一次我们继续selenium模块的介绍与使用。" class="headerlink" title="本次的内容就到这里了，下一次我们继续selenium模块的介绍与使用。"></a><strong>本次的内容就到这里了，下一次我们继续selenium模块的介绍与使用。</strong></h1>]]></content>
      <tags>
        <tag>python</tag>
        <tag>技术</tag>
        <tag>web自动化</tag>
      </tags>
  </entry>
  <entry>
    <title>第一次爬虫实战——爬取你喜欢的小说</title>
    <url>/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/</url>
    <content><![CDATA[<p>第一次爬虫实战。</p>
<span id="more"></span>
<p>我们先随便在网上找一个能免费看小说的网站：</p>
<p><a href="https://www.biquke.vip/">https://www.biquke.vip/</a></p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026201714925.png" alt="image-20221026201714925" style="zoom:50%;"></p>
<p>点击一本书打开：</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026201806737.png" alt="image-20221026201806737" style="zoom:50%;"></p>
<p>随便挑一章进入：</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026201908715.png" alt="image-20221026201908715" style="zoom:50%;"></p>
<p>鼠标右键查看网页源代码：</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026202110642.png" alt="image-20221026202110642" style="zoom: 33%;"></p>
<p>我们先获取这一章的标题，Ctrl+F搜索<strong>小狗小泥人</strong>，发现有九个之多，我们随便选一个：</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026202551817.png" alt="image-20221026202551817" style="zoom:50%;"></p>
<p>再来看文本内容，搜索<strong>仙人指路</strong>，发现文本的内容都在一起，且格式十分的统一。</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026202702187.png" alt="image-20221026202702187" style="zoom: 50%;"></p>
<p>在知道了这些内容后我们就可以进行该章节的爬取了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">#设置输出为中文</span></span><br><span class="line">sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=<span class="string">&#x27;gb18030&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#=====================第一次爬虫实战，爬取小说=======================</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#小说某一章的地址</span></span><br><span class="line">url=<span class="string">&quot;https://www.biquke.vip/book/204/137492.html&quot;</span></span><br><span class="line"><span class="comment">#用get访问该地址</span></span><br><span class="line">resp=requests.get(url)</span><br><span class="line">设置解码格式为<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">resp.encoding=<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">创建beautifulsoup对象</span><br><span class="line">main_page=BeautifulSoup(resp.text,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"><span class="comment">#获取文件名，注意处理空格</span></span><br><span class="line">text_name=main_page.find(<span class="string">&quot;div&quot;</span>,class_=<span class="string">&quot;bookname&quot;</span>).find(<span class="string">&quot;h1&quot;</span>).get_text().strip()</span><br><span class="line"><span class="comment">#find_all返回的是一个列表，所以用列表解析式操作它</span></span><br><span class="line">texts=[text_tag.get_text().strip() <span class="keyword">for</span> text_tag <span class="keyword">in</span> main_page.find_all(<span class="string">&#x27;p&#x27;</span>,class_=<span class="string">&quot;content_detail&quot;</span>)]</span><br><span class="line"><span class="comment">#新建txt文件，文件名就用章节名，把内容写进去</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;text_name&#125;</span>.txt&quot;</span>,mode=<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">f&quot;<span class="subst">&#123;text_name&#125;</span>\n\n&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">        f.write(text+<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026211153129.png" alt="image-20221026211153129" style="zoom: 67%;"></p>
<p>我们成功的把这一章的内容爬取下来了！！</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/R-C1.jpg" alt="R-C1"></p>
<p>但是</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/R-C2.jpg" alt="R-C2"></p>
<p>我们的目标可不仅仅是小说的某一个章节，是整本小说，甚至更进一步爬取别的小说，一次我们就需要进行更深一步的分析：</p>
<p>我们先回到书的主界面，右键查看网页源代码，先分析我们需要什么，我们想要每一章的地址，这样我们就可以一章一章的爬取下来了，Ctrl+F搜索<strong>第一章</strong>，这个可能因为网站的原因，章节的编号有一点乱，但不影响。</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026224043323.png" alt="image-20221026224043323"></p>
<p>注意到<strong>第一章 小二上酒</strong>的上面有一个<strong>href=”/book/204/137470.html”</strong>，我们打开第一章对比一下：</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026224228382-16667980282272.png" alt="image-20221026224228382"></p>
<p>刚好就是第一章网址的后面部分，大家可以再对比几章，都是一样的结果，而且都是在<code>&lt;dd&gt;</code>标签下的<code>&lt;a&gt;</code>标签里，但是</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/R-C.jpg" alt="R-C"></p>
<p>我们注意到</p>
<p><img src="/2022/10/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%88%AC%E5%8F%96%E4%BD%A0%E5%96%9C%E6%AC%A2%E7%9A%84%E5%B0%8F%E8%AF%B4/image-20221026225112987.png" alt="image-20221026225112987"></p>
<p>它还有一个最新章节的东西，而且里面的章节下面也有，所以我们在搜索的时候，需要做一些限定。</p>
<p>我们可以把上面爬取一章内容的代码封装成一个函数。</p>
<p>完整代码附上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=<span class="string">&#x27;gb18030&#x27;</span>)</span><br><span class="line"><span class="comment">#第一次爬虫实战，爬取小说</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#小说某一章的地址</span></span><br><span class="line">url=<span class="string">&quot;https://www.biquke.vip/book/204/137492.html&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_novel_text</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="comment">#用get访问该地址</span></span><br><span class="line">    resp=requests.get(url)</span><br><span class="line"></span><br><span class="line">    resp.encoding=<span class="string">&quot;utf-8&quot;</span></span><br><span class="line"></span><br><span class="line">    main_page=BeautifulSoup(resp.text,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line">    text_name=main_page.find(<span class="string">&quot;div&quot;</span>,class_=<span class="string">&quot;bookname&quot;</span>).find(<span class="string">&quot;h1&quot;</span>).get_text().strip()</span><br><span class="line"></span><br><span class="line">    texts=[text_tag.get_text().strip() <span class="keyword">for</span> text_tag <span class="keyword">in</span> main_page.find_all(<span class="string">&#x27;p&#x27;</span>,class_=<span class="string">&quot;content_detail&quot;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;text_name&#125;</span>.txt&quot;</span>,mode=<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">f&quot;<span class="subst">&#123;text_name&#125;</span>\n\n&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">            f.write(text+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    f.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;text_name&#125;</span>下载完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    main_url=<span class="string">&quot;https://www.biquke.vip/book/204/&quot;</span></span><br><span class="line"></span><br><span class="line">    main_resp=requests.get(main_url)</span><br><span class="line"></span><br><span class="line">    main_page=BeautifulSoup(main_resp.text,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line">    urls=[tag.find(<span class="string">&#x27;a&#x27;</span>).get(<span class="string">&quot;href&quot;</span>) <span class="keyword">for</span> tag <span class="keyword">in</span> main_page.find_all(<span class="string">&quot;dd&quot;</span>)[<span class="number">12</span>:]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        get_novel_text(<span class="string">&quot;https://www.biquke.vip&quot;</span>+url)</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>就可以愉快的下载整本书阅读了！！，本程序还有很多细节可以优化——添加输入想要下载小说名字的功能，新建一个文件夹存放小说，过滤掉一些没有正文内容的章节，使用多线程加速下载…..感觉兴趣的话可以自己尝试。那么本篇内容就到此结束了，感谢各位的观看Thanks♪(･ω･)ﾉ。</p>
]]></content>
  </entry>
  <entry>
    <title>简简单单wordcloud</title>
    <url>/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/</url>
    <content><![CDATA[<p>你是否也在别人的PPT，报告中见过这样的图片：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/51a6d2522ed5653e6ec1a7e31912f6bc.jpg" alt="查看源图像" style="zoom: 50%;"></p>
<span id="more"></span>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/b9bf1015765765df91d497abd3e6dc74.jpg" alt="查看源图像" style="zoom: 50%;"></p>
<p>感觉很高大上，很牛逼，而苦恼于不清楚怎么去制作，没关系，万能的Python帮你解决。</p>
<h2 id="一-什么是词云"><a href="#一-什么是词云" class="headerlink" title="一.什么是词云"></a>一.什么是词云</h2><p> “词云”是对网络文本中出现频率较高的“关键词”予以视觉上的突出，形成“关键词云层”或“关键词渲染”，从而过滤掉大量的文本信息，使浏览网页者只要一眼扫过文本就可以领略文本的主旨。</p>
<p>词云”是数据可视化的一种形式。给出一段文本的关键词，根据关键词的出现频率而生成的一幅图像，人们只要扫一眼就能够明白文章主旨。</p>
<h2 id="二-wordcloud模块带你玩转词云"><a href="#二-wordcloud模块带你玩转词云" class="headerlink" title="二.wordcloud模块带你玩转词云"></a>二.wordcloud模块带你玩转词云</h2><h3 id="一-wordcloud简介与下载"><a href="#一-wordcloud简介与下载" class="headerlink" title="(一)wordcloud简介与下载"></a>(一)wordcloud简介与下载</h3><p>wordcloud是优秀的词云展示第三方库，以词语为基本单位，通过图形可视化的方式，更加直观和艺术的展示文本。</p>
<p>下载的话正常使用<code>pip install wordcloud</code>下载即可，用pip安装不了的见这篇文章：<a href="https://zhuanlan.zhihu.com/p/33507393">https://zhuanlan.zhihu.com/p/33507393</a></p>
<h3 id="二-wordcloud入门"><a href="#二-wordcloud入门" class="headerlink" title="(二)wordcloud入门"></a>(二)wordcloud入门</h3><p>首先从wordcloud库调用WordCloud方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br></pre></td></tr></table></figure>
<p>使用WordCloud方法创建一个wordcloud对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wd=WordCloud()</span><br></pre></td></tr></table></figure>
<p>我们让鼠标停留在WordCloud方法上即可详细查看其内容，WordCloud方法需要的参数如下图：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022002846635.png" alt="image-20221022002846635" style="zoom: 50%;"></p>
<p>下面我们介绍几个常用的参数：</p>
<p>1.<strong>height参数</strong>：生成词云图片的高度，默认为200；</p>
<p>2.<strong>width参数</strong>：生成词云图片的宽度，默认为400，可以和height参数一起使用</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">width</span>=<span class="number">400</span>,height=<span class="number">400</span>/<span class="number">1</span>.<span class="number">618</span></span><br></pre></td></tr></table></figure>
<p>将图片长宽比设置为黄金分割比；</p>
<p>3.<strong>background_color参数:</strong>背景颜色，这个想必不用我过多介绍，就是生成的词云图片的背景颜色，默认为黑色，我们可以设置<code>background_color=&quot;white&quot;</code>，将颜色设为白色；</p>
<p>4.<strong>repeat参数</strong>：表示单词是否可以重复出现，默认为False</p>
<p><strong>设置前</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"></span><br><span class="line">wd=WordCloud(background_color=<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.generate(<span class="string">&quot;hello world python java windows&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.to_file(<span class="string">&quot;1.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022075036132.png" alt="image-20221022075036132"></p>
<p><strong>设置后</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"></span><br><span class="line">wd=WordCloud(background_color=<span class="string">&quot;white&quot;</span>,repeat=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">wd.generate(<span class="string">&quot;hello world python java windows&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.to_file(<span class="string">&quot;1.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022075155099.png" alt="image-20221022075155099"></p>
<p>但我们发现，如果直接这样设置的话生成的字云有一点太密了，这时候就需要下一个参数max_words;</p>
<p>5.<strong>max_words参数</strong>：词云的最大单词数，默认为200；</p>
<p>6.<strong>max_font_size参数</strong>：单词的最大字号，还一个min_font_size,是最小字号，默认为4；</p>
<p>7.<strong>font_path参数</strong>：尝试运行一下这段代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"></span><br><span class="line">wd=WordCloud(background_color=<span class="string">&quot;white&quot;</span>,repeat=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">wd.generate(<span class="string">&quot;唱 跳 Rap 篮球 蔡徐坤&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.to_file(<span class="string">&quot;1.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>发现会得到这样的结果：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022101147647.png" alt="image-20221022101147647"></p>
<p>发现所有的汉字都变成了方框，这是因为他默认的字体是英文的，不能识别汉字，这时候，我们就需要用font_path参数吧中文字体引进来了。</p>
<p>你电脑里下载好的字体在这里：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022104312657.png" alt="image-20221022104312657" style="zoom:50%;"></p>
<p>选择一个中文字体即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"></span><br><span class="line">wd=WordCloud(font_path=<span class="string">&quot;C:\\Windows\\Fonts\\simsun.ttc&quot;</span>,background_color=<span class="string">&quot;white&quot;</span>,repeat=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">wd.generate(<span class="string">&quot;唱 跳 Rap 篮球 蔡徐坤&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.to_file(<span class="string">&quot;1.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022104644533.png" alt="image-20221022104644533"></p>
<p>8.<strong>colormap参数</strong>：词云单词的颜色，可以上<a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html选择，如我设置colormap为winter：">https://matplotlib.org/stable/tutorials/colors/colormaps.html选择，如我设置colormap为winter：</a></p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022121327227.png" alt="image-20221022121327227"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wd=WordCloud(font_path=<span class="string">&quot;C:\\Windows\\Fonts\\simsun.ttc&quot;</span>,background_color=<span class="string">&quot;white&quot;</span>,repeat=<span class="literal">True</span>,colormap=<span class="string">&#x27;winter&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022121353015.png" alt="image-20221022121353015"></p>
<p>除此之外，还有各种各样的colormap可以选择</p>
<p>除此之外，也可以自制配色：</p>
<p>这种方法需要从图片中提取配色，例如我想用这张图片的配色：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022232842173.png" alt="image-20221022232842173" style="zoom:80%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> ImageColorGenerator</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">colors=np.array(Image.<span class="built_in">open</span>(<span class="string">&quot;780.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">color_map=ImageColorGenerator(colors)</span><br></pre></td></tr></table></figure>
<p>我们通过将图片转化为array数组来获取它的RGB三通道值，再用wordcloud自带的ImageColorGenerator函数将其转为配色，注意这时候就不能再用colormap参数了，这时候得使用color_func参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span>  ImageColorGenerator</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">colors=np.array(Image.<span class="built_in">open</span>(<span class="string">&quot;780.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">color_map=ImageColorGenerator(colors)</span><br><span class="line"></span><br><span class="line">wd=WordCloud(font_path=<span class="string">&quot;C:\\Windows\\Fonts\\simsun.ttc&quot;</span>,background_color=<span class="string">&quot;white&quot;</span>,repeat=<span class="literal">True</span>,color_func=color_map)</span><br><span class="line"></span><br><span class="line">wd.generate(<span class="string">&quot;唱 跳 Rap 篮球 蔡徐坤&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.to_file(<span class="string">&quot;1.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果图：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022233659654.png" alt="image-20221022233659654"></p>
<p>快用这种方法用你喜欢的配色来制作词云吧！！</p>
<p>9，<strong>mask参数</strong>：给词云生成轮廓用的参数,不需要做成轮廓的背景应为白色，如这是博主利用PS做的一张图片：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221022235831471.png" alt="image-20221022235831471" style="zoom: 25%;"></p>
<p>将图片转化为array数组的形式，传给mask参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span>  ImageColorGenerator</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">mask=np.array(Image.<span class="built_in">open</span>(<span class="string">&quot;cxk.png&quot;</span>))</span><br><span class="line"></span><br><span class="line">wd=WordCloud(font_path=<span class="string">&quot;C:\\Windows\\Fonts\\simsun.ttc&quot;</span>,background_color=<span class="string">&quot;white&quot;</span>,repeat=<span class="literal">True</span>,mask=mask,max_words=<span class="number">150</span>)</span><br><span class="line"></span><br><span class="line">wd.generate(<span class="string">&quot;唱 跳 Rap 篮球 蔡徐坤&quot;</span>)</span><br><span class="line"></span><br><span class="line">wd.to_file(<span class="string">&quot;1.png&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>得到的结果图如下：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221023000022538.png" alt="image-20221023000022538" style="zoom:25%;"></p>
<p>运行过程可能会有点慢，这是很正常的，注意如果要自定义配色和定义边框的话，两张图片的大小需要一致；</p>
<p>10.<strong>counter_width参数</strong>：我们注意到之前生成的图虽然有了边框，但只有一个大致的形状，想要把边框用直线画出来，就需要设置这个参数我们设置<code>contour_width=3</code>，得到的结果为：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221023001619859.png" alt="image-20221023001619859" style="zoom:25%;"></p>
<p>图片有了黑色的线条做边框，此外还可以用counter_color参数设置边框的颜色；</p>
<p>11.<strong>mode参数</strong>：mode参数默认为RGB通道，如果我们想设置词云背景为透明，需要将mode设置为RGBA，background_color设置为None,生成结果为背景透明图片：</p>
<p><img src="/2022/10/21/%E7%AE%80%E7%AE%80%E5%8D%95%E5%8D%95wordcloud/image-20221023003740205.png" alt="image-20221023003740205" style="zoom:25%;"></p>
<p>这个黑色我也不知道为什么，注意wordcloud有个bug至今未修复，就是设置了透明背景就不能设置counter_width和color,因为通道个数不匹配。</p>
<p>此外wordcloud还有两个重要的函数generate和to_file，generate是以字符串为参数把字符串变成词云，而to_file函数顾名思义就是将生成的词云保存到本地，参数是一个字符串，表示到处结果的路径。</p>
<h1 id="以上就是如何利用wordcloud模块制作词云的教程了，一般来说生成词云的单词并不会直接给出，需要我们从一大段文本中自己提取关键词，这时候就需要Python的另一个文本处理模块jieba了，本次的内容就到处结束了，希望大家积极评论，Thanks♪-･ω･-ﾉ"><a href="#以上就是如何利用wordcloud模块制作词云的教程了，一般来说生成词云的单词并不会直接给出，需要我们从一大段文本中自己提取关键词，这时候就需要Python的另一个文本处理模块jieba了，本次的内容就到处结束了，希望大家积极评论，Thanks♪-･ω･-ﾉ" class="headerlink" title="以上就是如何利用wordcloud模块制作词云的教程了，一般来说生成词云的单词并不会直接给出，需要我们从一大段文本中自己提取关键词，这时候就需要Python的另一个文本处理模块jieba了，本次的内容就到处结束了，希望大家积极评论，Thanks♪(･ω･)ﾉ"></a>以上就是如何利用wordcloud模块制作词云的教程了，一般来说生成词云的单词并不会直接给出，需要我们从一大段文本中自己提取关键词，这时候就需要Python的另一个文本处理模块jieba了，本次的内容就到处结束了，希望大家积极评论，Thanks♪(･ω･)ﾉ</h1>]]></content>
      <tags>
        <tag>python</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>把你的程序变成exe</title>
    <url>/2022/12/05/%E6%8A%8A%E4%BD%A0%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%8F%98%E6%88%90exe/</url>
    <content><![CDATA[<p>出门在外没带电脑，想在没安装python的电脑上运行程序怎么办？看看人家C语言，编译运行完天然自带一个.exe文件，在哪都能运行，python作为一门万能的语言，自然也有能力解决这个问题，本文教你如何快速将写好的.py文件转为.exe文件。</p>
<span id="more"></span>
<p>​
要想实现今天这个功能，我们需要一个第三方的python模块--pyinstaller，下载方法很简单，直接在电脑cmd命令行窗口或pycharm编译器的terminal窗口输入：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip <span class="keyword">install</span> pyinstaller</span><br></pre></td></tr></table></figure>
<p>即可。</p>
<p>​
下载完这个模块，那么你已经完成了任务的50%了，例如我们想打包new.py文件，只需在terminal窗口输入：</p>
<figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">pyinstaller -F <span class="keyword">new</span><span class="type"></span>.py</span><br></pre></td></tr></table></figure>
<p>执行上面命令，将看到详细的生成过程。当生成完成后，将会在此 app
目录下看到多了一个 dist 目录，并在该目录下看到有一个 app.exe
文件，这就是使用 PyInstaller 工具生成的 exe
程序。注意到我在pyinstaller后面加了一个-F，这是表示指定生成单独的 exe
文件,下表是一些常用的命令。</p>
<table>
<colgroup>
<col style="width: 31%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th>-h，--help</th>
<th>查看该模块的帮助信息</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-F，-onefile</td>
<td>产生单个的可执行文件</td>
</tr>
<tr class="even">
<td>-D，--onedir</td>
<td>产生一个目录（包含多个文件）作为可执行程序</td>
</tr>
<tr class="odd">
<td>-a，--ascii</td>
<td>不包含 Unicode 字符集支持</td>
</tr>
<tr class="even">
<td>-d，--debug</td>
<td>产生 debug 版本的可执行文件</td>
</tr>
<tr class="odd">
<td>-w，--windowed，--noconsolc</td>
<td>指定程序运行时不显示命令行窗口（仅对 Windows 有效）</td>
</tr>
<tr class="even">
<td>-c，--nowindowed，--console</td>
<td>指定使用命令行窗口运行程序（仅对 Windows 有效）</td>
</tr>
<tr class="odd">
<td>-o DIR，--out=DIR</td>
<td>指定 spec 文件的生成目录。如果没有指定，则默认使用当前目录来生成
spec 文件</td>
</tr>
<tr class="even">
<td>-p DIR，--path=DIR</td>
<td>设置 Python 导入模块的路径（和设置 PYTHONPATH
环境变量的作用相似）。也可使用路径分隔符（Windows 使用分号，Linux
使用冒号）来分隔多个路径</td>
</tr>
<tr class="odd">
<td>-n NAME，--name=NAME</td>
<td>指定项目（产生的
spec）名字。如果省略该选项，那么第一个脚本的主文件名将作为 spec
的名字</td>
</tr>
</tbody>
</table>
<h2 id="重点">重点</h2>
<p>本人在第一次尝试将文件打包成exe文件时，报了如下图的错：</p>
<figure>
<img src="/2022/12/05/%E6%8A%8A%E4%BD%A0%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%8F%98%E6%88%90exe/image-20221205165650124.png" alt="image-20221205165650124">
<figcaption aria-hidden="true">image-20221205165650124</figcaption>
</figure>
<p>上网查了很久，有说配置环境变量的，有说重启电脑的，有说重装pyinstaller模块的，各种参差不齐，但都不能解决我的问题。</p>
<p>但最后还是找到了一种解决办法，在系统的cmd命令行中使用次命令，但需要在前面加一个python
-m，完整代码如下：</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">python</span> -<span class="keyword">m</span> PyInstaller -F D:\<span class="keyword">new</span>.<span class="keyword">py</span></span><br></pre></td></tr></table></figure>
<p>注意路径尽量不要有中文，之后就可以欢快的运行了。</p>
<figure>
<img src="/2022/12/05/%E6%8A%8A%E4%BD%A0%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%8F%98%E6%88%90exe/image-20221205170359467.png" alt="image-20221205170359467">
<figcaption aria-hidden="true">image-20221205170359467</figcaption>
</figure>
<p>结果：</p>
<p><img src="/2022/12/05/%E6%8A%8A%E4%BD%A0%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%8F%98%E6%88%90exe/image-20221205170455135.png" alt="image-20221205170455135" style="zoom:150%;"></p>
<p>本次的内容就到这里了，最近比较忙，好久没更博客了，今天刚好有空，水一次博文，感谢大家支持ღ(
´･ᴗ･` )</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Web知识补充(一)</title>
    <url>/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/</url>
    <content><![CDATA[<h2 id="要想学好爬虫web网络的基本知识是必不可少的本文简单介绍了一些基础的网络知识">要想学好爬虫，web网络的基本知识是必不可少的，本文简单介绍了一些基础的网络知识</h2>
<span id="more"></span>
<p>！！！本文内容主要基于我最近看的崔庆才大佬的《Python3网络爬虫开发实战2》(强推！！）和网上的一些博客。</p>
<h2 id="一.uri和url">一.URI和URL</h2>
<p>URI(Uniform Resource
Identifier)又称统一资源标识符，是一个用于标识某一互联网资源名称的字符串，web上你能看到的任何资源：HTML文档，图片，视频.......都可以用URI来进行定位。</p>
<p>URL(Universal Resource
Locator)又叫统一资源定位符，用来表示互联网上的某个资源地址，也就是我们俗称的网址，URL是URI的子集，URI除了包括URL还包括URN(Uniform
Resource
Name)统一资源名称，正如它的名字，URN只为资源命名而不指导如何找到资源，而URL则指导我们去找到资源。</p>
<p>URL是有一定的格式规范的，基本的格式如下：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">protocol :<span class="regexp">//</span> hostname[:port] <span class="regexp">/ path /</span> [;parameters][?query]<span class="comment">#fragmen</span></span><br></pre></td></tr></table></figure>
<h4 id="protocol协议">1) protocol（协议）</h4>
<p>protocol 是指网络传输协议，常用的有http,http,ftp。</p>
<h4 id="hostname主机名">2) hostname（主机名）</h4>
<p>是指存放资源的服务器的域名、主机名或 IP
地址。<code>www.baidu.com</code>就是一个域名。</p>
<h4 id="port端口号">3) port（端口号）</h4>
<p>port 是一个可选的整数，它的取值范围 是
0-65535。如果该值被省略，则使用默认的端口号，例如http的默认端口号是80。</p>
<h4 id="path路由地址">4) path（路由地址）</h4>
<p>由零个或多个<code>/</code>符号隔开的字符串，一般用于网络资源在服务器中的地址。。</p>
<h4 id="query-查询">5) query (查询)</h4>
<p>查询，常以？开始，后面跟查询用的参数，多个参数之间用&amp;隔开，例如：<code>www.baidu.com/s?wd=爬虫</code>就表示查询"爬虫"有关的资源。</p>
<h4 id="fragment信息片断">6) fragment（信息片断）</h4>
<p>片段是对资源描述的部分补充，可以理解为资源内部的书签。</p>
<h2 id="二.http和https协议">二.http和https协议</h2>
<figure>
<img src="/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/image-20230223230959099.png" alt="image-20230223230959099">
<figcaption aria-hidden="true">image-20230223230959099</figcaption>
</figure>
<p>首先我们要知道什么是协议，<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE#:~:text=%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%20%E6%9C%AF%E8%AF%AD%E7%AE%80%E4%BB%8B.%20%E7%BC%96%E8%BE%91.%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%8C%87%E7%9A%84%E6%98%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BA%92%E7%9B%B8%E9%80%9A%E4%BF%A1%E7%9A%84%E5%AF%B9%E7%AD%89%E5%AE%9E%E4%BD%93%E4%B9%8B%E9%97%B4%E4%BA%A4%E6%8D%A2%E4%BF%A1%E6%81%AF%E6%97%B6%E6%89%80%E5%BF%85%E9%A1%BB%E9%81%B5%E5%AE%88%E7%9A%84%E8%A7%84%E5%88%99%E7%9A%84%E9%9B%86%E5%90%88%E3%80%82.%20%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE.,%E5%AF%B9%E7%AD%89%E5%AE%9E%E4%BD%93%E9%80%9A%E5%B8%B8%E6%98%AF%E6%8C%87%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B8%AD%E5%A4%84%E4%BA%8E%E7%9B%B8%E5%90%8C%E5%B1%82%E6%AC%A1%E7%9A%84%E4%BF%A1%E6%81%AF%E5%8D%95%E5%85%83%E3%80%82.%20%E4%B8%80%E8%88%AC%E7%B3%BB%E7%BB%9F%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%8C%85%E6%8B%AC%E4%BA%94%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A%E9%80%9A%E4%BF%A1%E7%8E%AF%E5%A2%83%EF%BC%8C%E4%BC%A0%E8%BE%93%E6%9C%8D%E5%8A%A1%EF%BC%8C%E8%AF%8D%E6%B1%87%E8%A1%A8%EF%BC%8C%E4%BF%A1%E6%81%AF%E7%9A%84%E7%BC%96%E7%A0%81%E6%A0%BC%E5%BC%8F%EF%BC%8C%E6%97%B6%E5%BA%8F%E3%80%81%E8%A7%84%E5%88%99%E5%92%8C%E8%BF%87%E7%A8%8B%E3%80%82.%201969%E5%B9%B4%E7%BE%8E%E5%9B%BD%E5%9B%BD%E9%98%B2%E9%83%A8%E5%BB%BA%E7%AB%8B%E6%9C%80%E6%97%A9%E7%9A%84%E7%BD%91%E7%BB%9C--%E9%98%BF%E5%B8%95%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%97%B6%EF%BC%8C%E5%8F%91%E5%B8%83%E4%BA%86%E4%B8%80%E7%BB%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%86%9B%E7%94%A8%E6%A0%87%E5%87%86%EF%BC%8C%E5%AE%83%E5%8C%85%E6%8B%AC%E4%BA%86%E4%BA%94%E4%B8%AA%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B9%A0%E6%83%AF%E4%B8%8A%E4%BB%A5%E5%85%B6%E4%B8%AD%E7%9A%84TCP%E5%92%8CIP%E4%B8%A4%E4%B8%AA%E5%8D%8F%E8%AE%AE%E4%BD%9C%E4%B8%BA%E8%BF%99%E7%BB%84%E5%8D%8F%E8%AE%AE%E7%9A%84%E9%80%9A%E7%A7%B0%E3%80%82.%20TCP%2FIP%E6%98%AF%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E6%AD%A3%E5%BC%8F%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%EF%BC%8C%E6%98%AF%E4%B8%80%E7%BB%84%E5%9C%A8%E8%AE%B8%E5%A4%9A%E7%8B%AC%E7%AB%8B%E4%B8%BB%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E6%8F%90%E4%BE%9B%E4%BA%92%E8%81%94%E5%8A%9F%E8%83%BD%E7%9A%84%E5%8D%8F%E8%AE%AE%EF%BC%8C%E8%A7%84%E8%8C%83%E5%9B%A0%E7%89%B9%E7%BD%91%E4%B8%8A%E6%89%80%E6%9C%89%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BA%92%E8%81%94%E6%97%B6%E7%9A%84%E4%BC%A0%E8%BE%93%E3%80%81%E8%A7%A3%E9%87%8A%E3%80%81%E6%89%A7%E8%A1%8C%E3%80%81%E4%BA%92%E6%93%8D%E4%BD%9C%EF%BC%8C%E8%A7%A3%E5%86%B3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BA%92%E8%81%94%E3%80%81%E4%BA%92%E9%80%9A%E3%80%81%E6%93%8D%E4%BD%9C%E6%80%A7%EF%BC%8C%E6%98%AF%E8%A2%AB%E5%85%AC%E8%AE%A4%E7%9A%84%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%9B%BD%E9%99%85%E5%B7%A5%E4%B8%9A%E6%A0%87%E5%87%86%E3%80%82.%20">百度</a>上给的定义为：网络协议为计算机网络中进行数据交换而建立的规则、标准或约定的集合。</p>
<h3 id="http协议">http协议</h3>
<p>http是Hyper Text Transfer
Protocol，超文本传输协议的缩写，是一种发布和接收 HTML
页面的方法，被用于在浏览器和网站服务器之间传递信息。http
协议以明文方式发送内容，不提供任何方式的数据加密，因此安全性较差，不适合传输密码之类的敏感信息。</p>
<h3 id="https协议">https协议</h3>
<p>https是HyperText Transfer Protocol over Secure Socket
Layer的缩写，可以理解为http+ssl，经由 http进行通信，但利用 ssl
来加密数据包，保护交换数据的隐私与完整性。</p>
<p>http原理示意图：</p>
<figure>
<img src="/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/image-20230223233322665.png" alt="image-20230223233322665">
<figcaption aria-hidden="true">image-20230223233322665</figcaption>
</figure>
<p>https原理：</p>
<figure>
<img src="/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/image-20230224002521728.png" alt="image-20230224002521728">
<figcaption aria-hidden="true">image-20230224002521728</figcaption>
</figure>
<p>http的版本也经历几代的更新，从最初的http0.9到http1.0到大部分网站使用的http1.1再到现在最新的http2.0，值得一提的是http2.0是建立在https协议基础上的，因此有一定的安全性，不少国内外的互联网公司已经开始使用http2.0.</p>
<p>我们先前所介绍的requests模块是不支持访问http2.0的网站的，会产生报错，如果想爬取基于http2.0的网站，则需要别的办法，我们之后会介绍。</p>
<p>如果你想查看一个网站是否使用http2.0协议，可以鼠标右键进入检查</p>
<figure>
<img src="/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/image-20230223235810123.png" alt="image-20230223235810123">
<figcaption aria-hidden="true">image-20230223235810123</figcaption>
</figure>
<p>找到网络</p>
<figure>
<img src="/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/image-20230223235841611.png" alt="image-20230223235841611">
<figcaption aria-hidden="true">image-20230223235841611</figcaption>
</figure>
<p>可以发现有一栏叫做协议，就可以看到该资源所使用的协议类型了。</p>
<p>如果没有协议这一栏的话可以吧鼠标放在栏与栏的分隔处，鼠标右键，标头选项，把协议一栏勾上就可以了。</p>
<h3 id="http请求方法">http请求方法</h3>
<p>请求方法是用于标识请求服务端的方式，http使用的请求方法如下图所示</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 9%">
<col style="width: 84%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">序号</th>
<th style="text-align: left;">方法</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">GET</td>
<td style="text-align: left;">请求指定的页面信息，并返回实体主体。</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">HEAD</td>
<td style="text-align: left;">类似于 GET
请求，只不过返回的响应中没有具体的内容，用于获取报头</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">POST</td>
<td style="text-align: left;">向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST
请求可能会导致新的资源的建立和/或已有资源的修改。</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">PUT</td>
<td style="text-align: left;">从客户端向服务器传送的数据取代指定的文档的内容。</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">DELETE</td>
<td style="text-align: left;">请求服务器删除指定的页面。</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">CONNECT</td>
<td style="text-align: left;">HTTP/1.1
协议中预留给能够将连接改为管道方式的代理服务器。</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7</td>
<td style="text-align: left;">OPTIONS</td>
<td style="text-align: left;">允许客户端查看服务器的性能。</td>
</tr>
<tr class="even">
<td style="text-align: left;">8</td>
<td style="text-align: left;">TRACE</td>
<td style="text-align: left;">回显服务器收到的请求，主要用于测试或诊断。</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9</td>
<td style="text-align: left;">PATCH</td>
<td style="text-align: left;">是对 PUT
方法的补充，用来对已知资源进行局部更新 。</td>
</tr>
</tbody>
</table>
<p>而我们最常用的是get和post两种请求手段，之前也有过介绍。我们同样可以在网络中看到资源的请求方法。</p>
<figure>
<img src="/2023/02/23/Web%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85/image-20230224150151787.png" alt="image-20230224150151787">
<figcaption aria-hidden="true">image-20230224150151787</figcaption>
</figure>
<p>具体的请求过程我会在之后的文章介绍，那么本文到这里就结束了，感谢各位阅读Thanks♪(･ω･)ﾉ</p>
]]></content>
      <tags>
        <tag>爬虫</tag>
        <tag>技术</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>条条XPATH通罗马</title>
    <url>/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/</url>
    <content><![CDATA[<h2 id="如果说正则表达式是暴力美学，万物皆可匹配，那么Xpath更像是针对XML文档的一把手术刀，精准的帮你一层层剥开XML文档修饰的外壳，直达元素所在。"><a href="#如果说正则表达式是暴力美学，万物皆可匹配，那么Xpath更像是针对XML文档的一把手术刀，精准的帮你一层层剥开XML文档修饰的外壳，直达元素所在。" class="headerlink" title="如果说正则表达式是暴力美学，万物皆可匹配，那么Xpath更像是针对XML文档的一把手术刀，精准的帮你一层层剥开XML文档修饰的外壳，直达元素所在。"></a>如果说正则表达式是暴力美学，万物皆可匹配，那么Xpath更像是针对XML文档的一把手术刀，精准的帮你一层层剥开XML文档修饰的外壳，直达元素所在。</h2><span id="more"></span>
<p><strong>XPath</strong>(XML Path Language) 是一门在 XML 文档中查找信息的语言。XML 指可扩展标记语言（Extensible Markup Language）。</p>
<p>XML 被设计用来传输和存储数据，不用于表现和展示数据，HTML 则用来表现数据。</p>
<p>但现在也可用于HTML文档的搜索。</p>
<p>下面我们通过python的lxml库，使用Xpath对HTML进行解析</p>
<p>lxml库是第三方库需要进行安装：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>
<p>在使用lxml库时我们这样调用，使用其中的etree模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br></pre></td></tr></table></figure>
<p>注意在引用etree时编译器可能会表上红色下划线，但其实程序可以正常运行，并不会报错,如果想要解决的话可以这样写：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> html</span><br><span class="line">etree=html.etree</span><br></pre></td></tr></table></figure>
<p>安装完成后我们就可以开始进行XPath的学习了。</p>
<p>XML文档和HTML文档可以看成一颗树，上面有许多的节点，下面给出XPath解析该树的一些常用规则(摘自<a href="https://www.runoob.com/xpath/xpath-syntax.html">菜鸟教程</a>)</p>
<h3 id="选取节点"><a href="#选取节点" class="headerlink" title="选取节点"></a>选取节点</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">表达式</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">nodename</td>
<td style="text-align:left">选取此节点的所有子节点。</td>
</tr>
<tr>
<td style="text-align:left">/</td>
<td style="text-align:left">从根节点选取（取子节点）。</td>
</tr>
<tr>
<td style="text-align:left">//</td>
<td style="text-align:left">从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置（取子孙节点）。</td>
</tr>
<tr>
<td style="text-align:left">.</td>
<td style="text-align:left">选取当前节点。</td>
</tr>
<tr>
<td style="text-align:left">..</td>
<td style="text-align:left">选取当前节点的父节点。</td>
</tr>
<tr>
<td style="text-align:left">@</td>
<td style="text-align:left">选取属性。</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">路径表达式</th>
<th style="text-align:left">结果</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">bookstore</td>
<td style="text-align:left">选取 bookstore 元素的所有子节点。</td>
</tr>
<tr>
<td style="text-align:left">/bookstore</td>
<td style="text-align:left">选取根元素 bookstore。注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！</td>
</tr>
<tr>
<td style="text-align:left">bookstore/book</td>
<td style="text-align:left">选取属于 bookstore 的子元素的所有 book 元素。</td>
</tr>
<tr>
<td style="text-align:left">//book</td>
<td style="text-align:left">选取所有 book 子元素，而不管它们在文档中的位置。</td>
</tr>
<tr>
<td style="text-align:left">bookstore//book</td>
<td style="text-align:left">选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。</td>
</tr>
<tr>
<td style="text-align:left">//@lang</td>
<td style="text-align:left">选取名为 lang 的所有属性。</td>
</tr>
</tbody>
</table>
</div>
<p>是不是还没开始就感觉很复杂，不用担心，如果你要找的节点不是网页后期JavaScript渲染上去的，那么你可以这样获得其XPath路径：</p>
<p>右键检查</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230228231322042.png" alt="image-20230228231322042"></p>
<p>点击圈起来的按钮</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230228231441798.png" alt="image-20230228231441798"></p>
<p>鼠标移到想要选中的元素上，单击</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230228231801224.png" alt="image-20230228231801224"></p>
<p>鼠标移到网页源码上的阴影区域，右键”复制”，”复制XPath”就可以啦。</p>
<p>当然，现在大部分的网站都会进行JS渲染，很多元素我们都是不能直接在网页源代码里找到的，所以这种方法我们目前还不是很用的到。下面我们正式开始使用XPath解析HTML文档。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;!Doctype html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">	&lt;meta http-equiv=<span class="string">&quot;Content-Type&quot;</span> content=<span class="string">&quot;text/html; charset=UTF-8&quot;</span> /&gt;</span><br><span class="line">	&lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span> /&gt;</span><br><span class="line">	&lt;title&gt;XML 语法 | 菜鸟教程&lt;/title&gt;</span><br><span class="line"></span><br><span class="line">  &lt;meta name=<span class="string">&#x27;robots&#x27;</span> content=<span class="string">&#x27;max-image-preview:large&#x27;</span> /&gt;</span><br><span class="line">&lt;link rel=<span class="string">&#x27;stylesheet&#x27;</span> <span class="built_in">id</span>=<span class="string">&#x27;classic-theme-styles-css&#x27;</span> href=<span class="string">&#x27;http://www.runoob.com/wp-includes/css/classic-themes.min.css?ver=1&#x27;</span> <span class="built_in">type</span>=<span class="string">&#x27;text/css&#x27;</span> media=<span class="string">&#x27;all&#x27;</span> /&gt;</span><br><span class="line">&lt;link rel=<span class="string">&quot;canonical&quot;</span> href=<span class="string">&quot;http://www.runoob.com/xml/xml-syntax.html&quot;</span> /&gt;</span><br><span class="line">&lt;meta name=<span class="string">&quot;keywords&quot;</span> content=<span class="string">&quot;XML 语法&quot;</span>&gt;</span><br><span class="line">&lt;meta name=<span class="string">&quot;description&quot;</span> content=<span class="string">&quot;XML 语法规则   XML 的语法规则很简单，且很有逻辑。这些规则很容易学习，也很容易使用。  XML 文档必须有根元素 XML 必须包含根元素，它是所有其他元素的父元素，比如以下实例中 root 就是根元素：   [mycode3 type=&amp;#039;xml&amp;#039;]         .....     [/mycode3]   以下实例中 note 是根元素：    [mycode3 type=&amp;#039;xml&amp;#039;..&quot;</span>&gt;</span><br><span class="line">		</span><br><span class="line">	&lt;link rel=<span class="string">&quot;shortcut icon&quot;</span> href=<span class="string">&quot;https://static.runoob.com/images/favicon.ico&quot;</span>&gt;</span><br><span class="line">	&lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;/wp-content/themes/runoob/style.css?v=1.170&quot;</span> <span class="built_in">type</span>=<span class="string">&quot;text/css&quot;</span> media=<span class="string">&quot;all&quot;</span> /&gt;	</span><br><span class="line">	&lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css&quot;</span> media=<span class="string">&quot;all&quot;</span> /&gt;	</span><br><span class="line">  &lt;!--[<span class="keyword">if</span> gte IE <span class="number">9</span>]&gt;&lt;!--&gt;</span><br><span class="line">  &lt;script src=<span class="string">&quot;https://cdn.staticfile.org/jquery/2.0.3/jquery.min.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">  &lt;!--&lt;![endif]--&gt;</span><br><span class="line">  &lt;!--[<span class="keyword">if</span> lt IE <span class="number">9</span>]&gt;</span><br><span class="line">     &lt;script src=<span class="string">&quot;https://cdn.staticfile.org/jquery/1.9.1/jquery.min.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">     &lt;script src=<span class="string">&quot;https://cdn.staticfile.org/html5shiv/r29/html5.min.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">  &lt;![endif]--&gt;</span><br><span class="line">  &lt;link rel=<span class="string">&quot;apple-touch-icon&quot;</span> href=<span class="string">&quot;https://static.runoob.com/images/icon/mobile-icon.png&quot;</span>/&gt;</span><br><span class="line">  &lt;meta name=<span class="string">&quot;apple-mobile-web-app-title&quot;</span> content=<span class="string">&quot;菜鸟教程&quot;</span>&gt;</span><br><span class="line">&lt;/head&gt;</span><br></pre></td></tr></table></figure>
<p>这是菜鸟教程网页的一部分源码，我们想要把他变成可供XPath解析的HTML文档，有以下两种方式：</p>
<h3 id="一-将str类型的text转为HTML"><a href="#一-将str类型的text转为HTML" class="headerlink" title="一.将str类型的text转为HTML"></a>一.将str类型的text转为HTML</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text=<span class="string">&quot;&lt;head&gt;......&lt;/head&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">html=etree.HTML(text)</span><br></pre></td></tr></table></figure>
<h3 id="二-将代码存在test-html文件里"><a href="#二-将代码存在test-html文件里" class="headerlink" title="二.将代码存在test.html文件里"></a>二.将代码存在test.html文件里</h3><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">htmel</span>=etree.parse(<span class="string">&#x27;./test.heml&#x27;</span>,etree.HTMLParser)</span><br></pre></td></tr></table></figure>
<p>转化完毕之后，我们就需要按上述的规则来解析HTML文档了。</p>
<p>和一般的树一样，HTML节点树的节点之间也有一下几种关系：父节点，子节点，先辈节点，后代节点，我们正是以此为依据来一点一点的解析节点树来获得我们所要的内容的。</p>
<h3 id="所有节点"><a href="#所有节点" class="headerlink" title="所有节点"></a>所有节点</h3><p>我们通常使用//来获得所有符合要求的节点，如果我们想要获得所有节点，可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=html.xpath(<span class="string">&#x27;//*&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301001455649.png" alt="image-20230301001455649"></p>
<p>得到了所有的节点。*代表对节点无限制条件，返回的结果是一个列表，列表里的元素均是Element类型，后面跟着节点的名字。</p>
<h3 id="子节点"><a href="#子节点" class="headerlink" title="子节点"></a>子节点</h3><p>子节点或者子孙节点我们可以使用/或//来获得，其中/获得的是当前节点的直接子节点，而//获得的是当前节点的所有子孙结点。例如我们获取第一层的所有子节点:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=html.xpath(<span class="string">&#x27;/*&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301081519838.png" alt="image-20230301081519838"></p>
<p>只有一个节点，也就是第一层的html节点。</p>
<p>而使用//*则能获得第一层往下的所有子孙节点，也就是所有的节点。</p>
<h3 id="父节点"><a href="#父节点" class="headerlink" title="父节点"></a>父节点</h3><p>想要查找上一层的父节点也很简单，我们可以使用..来完成，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=html.xpath(<span class="string">&#x27;//meta[@name=&quot;keywords&quot;]&#x27;</span>)</span><br><span class="line">result=result[<span class="number">0</span>].xpath(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>这段代码中我们先找了name属性为keywords的meta节点，再寻找他的父亲节点，结果如下;</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301112720948.png" alt="image-20230301112720948"></p>
<p>得到了head节点</p>
<p>我们同样可以使用parent::来寻找父亲节点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=html.xpath(<span class="string">&#x27;//meta[@name=&quot;keywords&quot;]&#x27;</span>)</span><br><span class="line">result=result[<span class="number">0</span>].xpath(<span class="string">&quot;parent::*&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h3 id="属性匹配"><a href="#属性匹配" class="headerlink" title="属性匹配"></a>属性匹配</h3><p>XPath语法中，采用@来匹配节点的属性值以进行筛选</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=html.xpath(<span class="string">&#x27;//meta[@name]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>上述代码筛出了所有含有name属性的meta节点，结果如下</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301114051765.png" alt="image-20230301114051765"></p>
<p>但如果仅仅这样去筛选的话，范围太大了，所以我们需要对具体属性的值进行筛选：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=html.xpath(<span class="string">&#x27;//meta[@name=&quot;robots&quot;]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301190834237.png" alt="image-20230301190834237"></p>
<p>就定位到了</p>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301190959434.png" alt="image-20230301190959434"></p>
<p>这个meta节点，注意定位时属性值要加上””或’’。</p>
<p>如果你在匹配值是有多个节点属性值相同，那么就不能在使用上面的方法了</p>
<h3 id="文本获取"><a href="#文本获取" class="headerlink" title="文本获取"></a>文本获取</h3><p>在网络爬虫中，我们往往关注的是标签里的文本内容，例如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;div <span class="keyword">class</span>=<span class="string">&quot;tab&quot;</span>  <span class="built_in">id</span>=<span class="string">&quot;cate0&quot;</span>&gt;&lt;i <span class="keyword">class</span>=<span class="string">&quot;fa fa-reorder&quot;</span>&gt;&lt;/i&gt; 全部教程&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>我们想要获取div节点中所夹的”全部教程”四字，可以使用text()方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">txt=html.xpath(<span class="string">&#x27;//text()&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(txt)</span><br></pre></td></tr></table></figure>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301193250578.png" alt="image-20230301193250578"></p>
<h3 id="属性获取"><a href="#属性获取" class="headerlink" title="属性获取"></a>属性获取</h3><p>属性的获取和属性的匹配其实有点像，只不过少去了[]方括号，</p>
<p>还是用上面的div节点为例，我们要获得i节点的class属性，可以这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">class_value=html.xpath(<span class="string">&#x27;//i/@class&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(class_value)</span><br></pre></td></tr></table></figure>
<p><img src="/2023/02/28/%E6%9D%A1%E6%9D%A1XPATH%E9%80%9A%E7%BD%97%E9%A9%AC/image-20230301195428121.png" alt="image-20230301195428121"></p>
<h2 id="后面还有一些复杂的操作，本章篇幅有限，我们以后再做讨论，Thanks♪-･ω･-ﾉ"><a href="#后面还有一些复杂的操作，本章篇幅有限，我们以后再做讨论，Thanks♪-･ω･-ﾉ" class="headerlink" title="后面还有一些复杂的操作，本章篇幅有限，我们以后再做讨论，Thanks♪(･ω･)ﾉ"></a>后面还有一些复杂的操作，本章篇幅有限，我们以后再做讨论，Thanks♪(･ω･)ﾉ</h2>]]></content>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>道高一尺，魔高一丈，再多的反爬手段也拦不住我火热的心(一)</title>
    <url>/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/</url>
    <content><![CDATA[<h2 id="白嫖使我快乐一切反对和压迫白嫖的都是我们的敌人">白嫖使我快乐，一切反对和压迫白嫖的都是我们的敌人！！</h2>
<h2 id="世纪伟大的科学家哲学家-沃兹基.硕德">——
21世纪伟大的科学家，哲学家 沃兹基.硕德</h2>
<span id="more"></span>
<p>在之前的博文中我们其实也提到过一些反反爬的手段，例如伪造UA头之类的，本次我们讲更详细的去介绍一些反爬手段和反制它们的方法。</p>
<figure>
<img src="https://ts1.cn.mm.bing.net/th/id/R-C.d62ee2cb57dd744f5c84d1812d39d8ef?rik=9sGTDW3tcIujJg&amp;riu=http%3a%2f%2fguangyuanol.cn%2fuploads%2fallimg%2f201003%2f16050A408-1.jpg&amp;ehk=ht%2bxoe4VhZO%2baaMLbSpH3hgwBfqgJagme3cYNmsqcmA%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" alt="白嫖是什么意思什么梗？ 网络用语白嫖的真实含义了解一下|白嫖|是什么-知识百科-川北在线">
<figcaption aria-hidden="true">白嫖是什么意思什么梗？
网络用语白嫖的真实含义了解一下|白嫖|是什么-知识百科-川北在线</figcaption>
</figure>
<h3 id="反爬虫简介">反爬虫简介</h3>
<p>使用爬虫虽然对使用者来说是一件很爽很便利的事，但是却令网站维护者，管理员十分头疼，因为爬虫频繁的发起请求会使网站的负担增大，一些个人搭建的小众网站的服务器可能就会因此崩溃，为了减少这些讨人厌的蛀虫，网站的搭建者们也是想尽办法绞尽脑汁用尽各种手段——也就是所谓的反爬手段来防止我们去白嫖网站上的信息。</p>
<p>如果说爬虫是使用任何技术手段，批量获取网站信息的一种方式，那么反爬就是使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。</p>
<p>反爬手段千千万，但大道归一，在高明的反爬手段也不外乎这两种:伪造网站数据和禁止用户请求。我们在平时爬虫时如果不在每次发送请求后sleep上一两秒，就很有可能因IP短时间内请求过频繁的被阻止请求，也就是第二类反爬手段。</p>
<h4 id="对于这些反爬手段聪明的反爬工作者们也在不断地进步想出新的办法来应对这些反爬手段其实爬和反爬只是一念之间往往会反爬的一定会爬虫会爬虫的也应定会反爬只是看他们的工作需要切换角色而已因此反爬的防线看似森严实际上早已漏洞百出只是马奇诺防线在我们掌握了技巧后可以很轻松的绕开下面我们就正式开始今天的内容">对于这些反爬手段，聪明的反爬工作者们也在不断地进步，想出新的办法来应对这些反爬手段，其实爬和反爬只是一念之间，往往会反爬的一定会爬虫，会爬虫的也应定会反爬，只是看他们的工作需要切换角色而已，因此，反爬的防线看似森严，实际上早已漏洞百出，只是"马奇诺防线"，在我们掌握了技巧后可以很轻松的绕开，下面我们就正式开始今天的内容。</h4>
<h3 id="user-agent验证反爬">User-Agent验证反爬</h3>
<p>User-Agent反爬虫指的是服务器端通过校验请求头中的User-Agent值来区分正常用户和爬虫程序的手段，这是一种较为初级的反爬虫手段。</p>
<p>User Agent中文名为用户代理，简称
UA。它包含了一个特征字符串，用来让网络协议的对端来识别发起请求的用户代理软件的应用类型、操作系统、软件开发商以及版本号。基本格式如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">User-Agent: <span class="tag">&lt;<span class="name">product</span>&gt;</span> / <span class="tag">&lt;<span class="name">product-version</span>&gt;</span> <span class="tag">&lt;<span class="name">comment</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>浏览器常用的格式如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">User-Agent: Mozilla/<span class="tag">&lt;<span class="name">version</span>&gt;</span> (<span class="tag">&lt;<span class="name">system-information</span>&gt;</span>) <span class="tag">&lt;<span class="name">platform</span>&gt;</span> (<span class="tag">&lt;<span class="name">platform-details</span>&gt;</span>) <span class="tag">&lt;<span class="name">extensions</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>以我们常用的Chorme浏览器为例，在Windows环境下Chorme浏览器的UA头如下：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Mozilla</span>/<span class="number">5</span>.<span class="number">0</span> (Windows NT <span class="number">10</span>.<span class="number">0</span>; Win64; x64) AppleWebKit/<span class="number">537</span>.<span class="number">36</span> (KHTML, like Gecko) Chrome/<span class="number">110.0.0.0</span> Safari/<span class="number">537</span>.<span class="number">36</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Mozilla/5.0</strong> 是一个通用标记符号，用来表示与 Mozilla
兼容，这几乎是现代浏览器的标配。</li>
</ul>
<p>而如果是爬虫的话，则不会显示这些信息,使用Python中的Requests库向服务器发起HTTP请求时服务器读取的UA是：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">python</span>-requests/<span class="number">2</span>.<span class="number">21</span>.<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>因此要想实现UA反爬的话只需要设置将"python"等关键词加入黑名单，在读取UA时只要发现黑名单上的出现，那么就认为遇到了爬虫，服务器就会阻止此次请求，但这种手段也仅仅只能防住一些练习时长两天半的新手爬虫练习生，而对付那些练习时长两年半的老练习生是远远不够的。</p>
<p>以一个<a href="https://antispider2.scrape.center/">爬虫训练网站</a>为例，这个网站采用了UA反爬：</p>
<p>我们如果直接去请求网页的源代码，并不能得到正确的源码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">resp=requests.get(<span class="string">&quot;https://antispider2.scrape.center/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.status_code)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230305202830801.png" alt="image-20230305202830801">
<figcaption aria-hidden="true">image-20230305202830801</figcaption>
</figure>
<p>正常如果请求到了网站的源代码，返回的状态码应该是200，而本次请求返回的状态码为403，表示服务器理解请求客户端的请求，但是拒绝执行此请求，更多详细的状态码可以查看<a href="https://www.runoob.com/http/http-status-codes.html">菜鸟教程</a></p>
<p>在这种没有得到正确网页源码的情况下我们最应优先考虑的就是UA反爬，处理UA反爬的方式也很简单，我们只需要伪造一个UA头，随着我们的请求一起发送过去，让服务器以为我们是用浏览器登录的即可。</p>
<p>具体方式如下：</p>
<h4 id="一.从浏览器上复制一个ua">一.从浏览器上复制一个UA</h4>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230305225358162.png" alt="image-20230305225358162">
<figcaption aria-hidden="true">image-20230305225358162</figcaption>
</figure>
<p>复制下来使用即可，把他添加到请求头里：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">resp=requests.get(<span class="string">&quot;https://antispider2.scrape.center/&quot;</span>,headers=header)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.status_code)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230305225543819.png" alt="image-20230305225543819">
<figcaption aria-hidden="true">image-20230305225543819</figcaption>
</figure>
<p>我们发现请求就能正常通过了，也能正常获得网页源码。</p>
<h4 id="二.用fake_useragent库伪造一个">二.用fake_useragent库伪造一个</h4>
<p>fake_useragent库，库如其名，是专门用来造假的user-agent的，它使用起来也很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> fake_useragent</span><br><span class="line"></span><br><span class="line">ua=fake_useragent.UserAgent()</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: ua.random</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">resp=requests.get(<span class="string">&quot;https://antispider2.scrape.center/&quot;</span>,headers=header)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.status_code)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>
<p>先构造一个UserAgent对象，在随便从里面选一个使用即可</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230305231516177.png" alt="image-20230305231516177">
<figcaption aria-hidden="true">image-20230305231516177</figcaption>
</figure>
<p>也是能获得到正确的网页源代码。</p>
<h4 id="重定向反爬">重定向反爬</h4>
<p>重定向是一个很广泛的概念，即通过各种方法将各种网络请求重新定个方向转到其它位置，比如网页重定向、域名重定向、数据报文重定向等。</p>
<p>在我们日常学习工作时，也常常会遇到这样的情况：看到一个好的网站，把它保存了下来，结果下一次点进去的时候却跳转到别的地方去了，这就是遇到了重定向，网站的维护者希望你是从它的主页进去的，而不希望你直接进入，所以你在请求此网页时，他会检测你前一个网站的信息，如果是首页的信息，他就允许你的请求，反之则拒绝，我们直接看一个例子：</p>
<p>这是一个爬虫练习的网站：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306230902756.png" alt="image-20230306230902756">
<figcaption aria-hidden="true">image-20230306230902756</figcaption>
</figure>
<p>第一个挑战是UA与referer校验反爬，Referer就是上一个页面的地址，这个是浏览器会在点击一个链接时自动添加到请求头中的，UA反爬怎么处理我们已经讲过了，我们就着重来看看后面的referer校验反爬：</p>
<p>我们打开第一关：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306232002255.png" alt="image-20230306232002255">
<figcaption aria-hidden="true">image-20230306232002255</figcaption>
</figure>
<p>尝试爬取一下他的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">heeader=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp=requests.get(<span class="string">&quot;http://www.spiderbuf.cn/n01/&quot;</span>，headers=header)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.status_code)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>
<p>结果是：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306232300133.png" alt="image-20230306232300133">
<figcaption aria-hidden="true">image-20230306232300133</figcaption>
</figure>
<p>我们发现状态码是200，说明我们的请求成功了，但得到的源代码却不太对，仔细一看，这不是训练场首页的源代码吗，</p>
<p>我们尝试直接打开一下它的链接，发现直接调到了网站首页，这时候我们就知道是遇上重定向了，这时候我们看一下两次网站的请求有什么区别：</p>
<p>直接进入链接：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306233201136.png" alt="image-20230306233201136">
<figcaption aria-hidden="true">image-20230306233201136</figcaption>
</figure>
<p>从首页进入的：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306233238757.png" alt="image-20230306233238757">
<figcaption aria-hidden="true">image-20230306233238757</figcaption>
</figure>
<p>我们注意到直接进入是有一个名为"n01/"的请求状态码为307，我们查询的307是临时重定向，与302类似，使用GET请求重定向，</p>
<p>那么我们该怎么解决重定向问题呢，答案也很简单，他需要什么，我们就给他什么，他想让我们先进入首页，我们不妨伪造信息让他以为我们进入过首页，我们比较一下两次"n01/"请求的请求头文件：</p>
<p>直接进入链接：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306233604186.png" alt="image-20230306233604186">
<figcaption aria-hidden="true">image-20230306233604186</figcaption>
</figure>
<p>从首页进入的：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306233623552.png" alt="image-20230306233623552">
<figcaption aria-hidden="true">image-20230306233623552</figcaption>
</figure>
<p>发现请求成功的请求头里多了一个referer参数，这正是前一个网站的网址，那么我们在请求的时候，也只要加上这个参数给他发送过去就行了，话不多说，我们动手试一试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">heeader=&#123;</span><br><span class="line">    <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;http://www.spiderbuf.cn/list&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resp=requests.get(<span class="string">&quot;http://www.spiderbuf.cn/n01/&quot;</span>,headers=heeader)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(resp.status_code)</span><br><span class="line"><span class="built_in">print</span>(resp.text)</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure>
<img src="/2023/03/03/%E9%81%93%E9%AB%98%E4%B8%80%E5%B0%BA%EF%BC%8C%E9%AD%94%E9%AB%98%E4%B8%80%E4%B8%88%EF%BC%8C%E5%86%8D%E5%A4%9A%E7%9A%84%E5%8F%8D%E7%88%AC%E6%89%8B%E6%AE%B5%E4%B9%9F%E6%8B%A6%E4%B8%8D%E4%BD%8F%E6%88%91%E7%81%AB%E7%83%AD%E7%9A%84%E5%BF%83/image-20230306234208955.png" alt="image-20230306234208955">
<figcaption aria-hidden="true">image-20230306234208955</figcaption>
</figure>
<p>正是目标网站的源代码，说明我们这次是彻彻底底的是成功了。</p>
<h3 id="总结一下本次讲的反爬手段主要是验证信息方面的反爬手段千千万还有类似动态加载之类的我们以后会经常遇到其他的反爬手段我们以后还会进行介绍thanksωﾉ">总结一下，本次讲的反爬手段主要是验证信息方面的，反爬手段千千万，还有类似动态加载之类的我们以后会经常遇到，其他的反爬手段我们以后还会进行介绍，Thanks♪(･ω･)ﾉ</h3>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>那年，我们一起爬过的文件</title>
    <url>/2023/03/08/%E9%82%A3%E5%B9%B4%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E7%88%AC%E8%BF%87%E7%9A%84%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="大家学习爬虫是为了爬哪些东西呢作者学习爬虫肯定是为了批量下载一些学习资源啊本文就来探讨一下怎么存储获得的学习资源">大家学习爬虫是为了爬哪些东西呢？作者学习爬虫，肯定是为了批量下载一些"学习资源"啊。本文就来探讨一下，怎么存储获得的学习资源。</h2>
<span id="more"></span>
<h3 id="txt文本文件存储">TXT文本文件存储</h3>
<p>文本，不仅是我们日常生活最常见的数据，应该也是我们在爬虫中遇到的最多的数据类型了，小说，数据，往往都是以文本的形式藏在网页源代码之中。</p>
<p>通常，对于文本数据，我们习惯用TXT文件去存储。</p>
<p>要想去操作一个文本文件，其他文件也一样，实现创建，添加，修改，等操作，我们首先应该打开这个文件，打开文件的方法很简单，就是使用python自带的open()函数，常用的语法是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(filename,mode) <span class="keyword">as</span> f:</span><br><span class="line">	file_operation</span><br></pre></td></tr></table></figure>
<p>with语法会保证在语句段结束的最后，自动调用一个exit方法，在这里就是结束后会自动加上一个close()方法，关闭打开的文件，</p>
<p>open函数常用的有两个参数，第一个参数是filename，是打开文件的路径，是一个字符串，第二个参数mode代表对文件进行操作的模式，具体有如下几种：</p>
<p><strong>r</strong>:read，以只读格式打开文件，只能读取数据，不能写入；</p>
<p><strong>rb</strong>:以二进制只读格式打开文件；</p>
<p><strong>r+</strong>:以读写格式打开文件，既可以读入数据，也可以写入；</p>
<p><strong>rb+</strong>:以二进制读写格式打开文件；</p>
<p><strong>w</strong>:write，以写入方式打开一个文件，文件存在则覆盖已有内容，文件不存在的新建文件；</p>
<p><strong>wb</strong>:以二进制写入方式打开一个文件；</p>
<p><strong>w+</strong>:以读写方式打开一个文件，文件存在则覆盖已有内容，文件不存在的新建文件；</p>
<p><strong>wb+</strong>:以二进制读写方式打开一个文件；</p>
<p><strong>a</strong>:以追加方式打开一个文件，如果文件已存在，则在文件的最后追加内容，如果文件不存在，则新建文件；</p>
<p><strong>ab</strong>:以二进制追加方式打开一个文件；</p>
<p><strong>a+</strong>:以读写方式打开一个文件，文件打开时是追加模式；</p>
<p><strong>ab+</strong>:以二进制读写方式打开一个文件，文件打开时是追加模式；</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>知识</tag>
        <tag>文件</tag>
      </tags>
  </entry>
  <entry>
    <title>一文搞定GPS接收机定位</title>
    <url>/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/</url>
    <content><![CDATA[<h2 id="结课大作业希望对大家有所帮助">结课大作业，希望对大家有所帮助</h2>
<span id="more"></span>
<h2 id="什么是gps接收机">什么是GPS接收机</h2>
<p>GPS接收机是接收全球定位系统卫星信号并确定地面空间位置的仪器。GPS卫星发送的导航定位信号，是一种可供无数用户共享的信息资源。对于陆地、
海洋和空间的广大用户，只要拥有能够接收、跟踪、变换和测量GPS信号的接收设备，
即GPS信号接收机。</p>
<p>一般的GPS接收机长这样：</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/resize,m_lfit,w_536,limit_1.jpeg" alt="GPS 接收机">
<figcaption aria-hidden="true">GPS 接收机</figcaption>
</figure>
<p>而我们今天要用的就比较简陋了，它长这样</p>
<p>使用其usb串口与电脑相连，并进行相关环境的配置，我们就可以用电脑接受其数据流了。</p>
<h2 id="数据流解读">数据流解读</h2>
<h3 id="gps接收机协议">GPS接收机协议</h3>
<p>我们利用GPS接收机接收到的数据流格式是基于NMEA-0183
协议，NMEA协议是为了在不同的GPS（全球定位系统）导航设备中建立统一的BTCM（海事无线电技术委员会）标准，由美国国家海洋电子协会（NMEA-The
National Marine Electronics
Associa-tion）制定的一套通讯协议。GPS接收机根据NMEA-0183协议的标准规范，将位置、速度等信息通过串口传送到PC机、MCU等设备。</p>
<p>NMEA-0183 协议是目前 GPS 接收机上使用最广泛的协议，大多数常见的 GPS
接收机、GPS 数据处理软件、导航软件都遵守或者至少兼容这个协议。</p>
<p><strong>数据格式</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$信息类型，x，x，x，x，x，x，x，x，x，x，x，x，x</span><br></pre></td></tr></table></figure>
<ul>
<li><code>$</code> 为起始标志；</li>
<li><code>,</code> 为域分隔符；</li>
<li><code>*</code> 为校验和识别符，其后两位数为校验和，代表了
<code>$</code>和 <code>*</code>
之间所有字符的按位异或值（不包括这两个字符）；</li>
<li><code>\r\n</code> 为终止符（不可见），所有的语句必须以来结束，也就是
ASCII 字符的“回车”（十六进制的 <code>0D</code>）和“换行”（十六进制的
<code>0A</code>）。</li>
</ul>
<p>NMEA-0183 协议定义的语句非常多，但是常用的或者说兼容性最广的语句只有
GPGGA、GPGSA、GPGSV、GPRMC、GPVTG、GPGLL 等。下面给出这些常用 NMEA 0183
语句的字段定义解释：</p>
<h3 id="gprmc"><strong>GPRMC</strong></h3>
<p>Recommended Minimum Specific GPS/TRANSIT Data（RMC）推荐定位信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$GPRMC</span>,&lt;1&gt;,&lt;2&gt;,&lt;3&gt;,&lt;4&gt;,&lt;5&gt;,&lt;6&gt;,&lt;7&gt;,&lt;8&gt;,&lt;9&gt;,&lt;10&gt;,&lt;11&gt;,&lt;12&gt;*hh</span><br></pre></td></tr></table></figure>
<p>各字段描述如下：</p>
<ul>
<li><code>&lt;1&gt;</code> UTC 时间，格式
hhmmss.ssss，代表时分秒.毫秒</li>
<li><code>&lt;2&gt;</code> 定位状态，A=有效定位，V=无效定位</li>
<li><code>&lt;3&gt;</code> 纬度 ddmm.mmmm（度分）格式（前面的 0
也将被传输）</li>
<li><code>&lt;4&gt;</code> 纬度半球 N（北纬）或 S（南纬）</li>
<li><code>&lt;5&gt;</code> 经度 dddmm.mmmm（度分）格式（前面的 0
也将被传输）</li>
<li><code>&lt;6&gt;</code> 经度半球 E（东经）或 W（西经）</li>
<li><code>&lt;7&gt;</code> 地面速率（000.0~999.9 节，前面的 0
也将被传输）</li>
<li><code>&lt;8&gt;</code>
地面航向（方位角），等效于二维罗盘（000.0~359.9
度，以真北为参考基准，前面的 0 也将被传输）</li>
<li><code>&lt;9&gt;</code> UTC 日期，DDMMYY（日月年）格式</li>
<li><code>&lt;10&gt;</code> 磁偏角（000.0~180.0 度，前面的 0
也将被传输）</li>
<li><code>&lt;11&gt;</code> 磁偏角方向，E（东）或 W（西）</li>
<li><code>&lt;12&gt;</code> 模式指示（仅 NMEA0183 3.0
版本输出，A=自主定位，D=差分，E=估算，N=数据无效）</li>
<li>最后两个字节是校验和</li>
</ul>
<p>注意：</p>
<ul>
<li>如果字段 4 的值等于 N，则字段 3 的值等于 ddmm.mmmmmm</li>
<li>如果字段 4 的值等于 S，则字段 3 的值等于 -ddmm.mmmmmm</li>
<li>如果字段 6 的值等于 E，则字段 5 的值等于 ddmm.mmmmmm</li>
<li>如果字段 6 的值等于 W，则字段 5 的值等于 -ddmm.mmmmmm</li>
<li>十进制北纬度数 = dd + mm.mmmmmm/60</li>
<li>十进制南纬度数 = -(dd + mm.mmmmmm/60)</li>
<li>十进制东经度数 = ddd + mm.mmmmmm/60</li>
<li>十进制西经度数 = -(ddd + mm.mmmmmm/60)</li>
</ul>
<h3 id="gpgga"><strong>GPGGA</strong></h3>
<p>Global Positioning System Fix Data（GGA）GPS定位信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$GPGGA</span>,&lt;1&gt;,&lt;2&gt;,&lt;3&gt;,&lt;4&gt;,&lt;5&gt;,&lt;6&gt;,&lt;7&gt;,&lt;8&gt;,&lt;9&gt;,M,&lt;10&gt;,M,&lt;11&gt;,&lt;12&gt;*hh</span><br></pre></td></tr></table></figure>
<p>各字段描述如下：</p>
<ul>
<li><code>&lt;1&gt;</code> UTC 时间，hhmmss（时分秒）格式</li>
<li><code>&lt;2&gt;</code> 纬度 ddmm.mmmm（度分）格式（前面的 0
也将被传输）</li>
<li><code>&lt;3&gt;</code> 纬度半球 N（北纬）或 S（南纬）</li>
<li><code>&lt;4&gt;</code> 经度 dddmm.mmmm（度分）格式（前面的 0
也将被传输）</li>
<li><code>&lt;5&gt;</code> 经度半球 E（东经）或 W（西经）</li>
<li><code>&lt;6&gt;</code> GPS
状态：0=未定位，1=非差分定位，2=差分定位，6=正在估算</li>
<li><code>&lt;7&gt;</code> 正在使用解算位置的卫星数量（00~12）（前面的 0
也将被传输）</li>
<li><code>&lt;8&gt;</code> HDOP 水平精度因子（0.5~99.9）</li>
<li><code>&lt;9&gt;</code> 海拔高度（-9999.9~99999.9）</li>
<li><code>&lt;10&gt;</code> 地球椭球面相对大地水准面的高度</li>
<li><code>&lt;11&gt;</code>
差分时间（从最近一次接收到差分信号开始的秒数，如果不是差分定位将为空）</li>
<li><code>&lt;12&gt;</code> 差分站 ID 号 0000~1023（前面的 0
也将被传输，如果不是差分定位将为空）</li>
</ul>
<h3 id="gpgsa"><strong>GPGSA</strong></h3>
<p>GPS DOP and Active Satellites（GSA）当前卫星信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$GPGSA</span>,&lt;1&gt;,&lt;2&gt;,&lt;3&gt;,&lt;3&gt;,,,,,&lt;3&gt;,&lt;3&gt;,&lt;3&gt;,&lt;4&gt;,&lt;5&gt;,&lt;6&gt;,&lt;7&gt;</span><br></pre></td></tr></table></figure>
<p>各字段描述如下：</p>
<ul>
<li><code>&lt;1&gt;</code> 模式 ：M = 手动， A = 自动。</li>
<li><code>&lt;2&gt;</code> 定位型式 1 = 未定位， 2 = 二维定位， 3 =
三维定位。</li>
<li><code>&lt;3&gt;</code> PRN 数字：01 至 32
表天空使用中的卫星编号，最多可接收 12 颗卫星信息。</li>
<li><code>&lt;4&gt;</code> PDOP 位置精度因子（0.5~99.9）</li>
<li><code>&lt;5&gt;</code> HDOP 水平精度因子（0.5~99.9）</li>
<li><code>&lt;6&gt;</code> VDOP 垂直精度因子（0.5~99.9）</li>
<li><code>&lt;7&gt;</code> Checksum（检查位）</li>
</ul>
<h3 id="gpvtg"><strong>GPVTG</strong></h3>
<p>Track Made Good and Ground Speed（VTG）地面速度信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$GPVTG</span>,&lt;1&gt;,T,&lt;2&gt;,M,&lt;3&gt;,N,&lt;4&gt;,K,&lt;5&gt;*hh</span><br></pre></td></tr></table></figure>
<p>各字段描述如下：</p>
<ul>
<li><code>&lt;1&gt;</code> 以真北为参考基准的地面航向（000~359
度，前面的 0 也将被传输）</li>
<li><code>&lt;2&gt;</code> 以磁北为参考基准的地面航向（000~359
度，前面的 0 也将被传输）</li>
<li><code>&lt;3&gt;</code> 地面速率（000.0~999.9 节，前面的 0
也将被传输）</li>
<li><code>&lt;4&gt;</code> 地面速率（0000.0~1851.8
公里/小时，前面的0也将被传输）</li>
<li><code>&lt;5&gt;</code> 模式指示（仅 NMEA 0183 3.0
版本输出，A=自主定位，D=差分，E=估算，N=数据无效）</li>
</ul>
<h3 id="gpgsv"><strong>GPGSV</strong></h3>
<p>GPS Satellites in View（GSV）可见卫星信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$GPGSV</span>, &lt;1&gt;,&lt;2&gt;,&lt;3&gt;,&lt;4&gt;,&lt;5&gt;,&lt;6&gt;,&lt;7&gt;,?&lt;4&gt;,&lt;5&gt;,&lt;6&gt;,&lt;7&gt;,&lt;8&gt;</span><br></pre></td></tr></table></figure>
<p>各字段描述如下：</p>
<ul>
<li><code>&lt;1&gt;</code> GSV语句的总数</li>
<li><code>&lt;2&gt;</code> 本句GSV的编号</li>
<li><code>&lt;3&gt;</code> 可见卫星的总数，00 至 12。</li>
<li><code>&lt;4&gt;</code> 卫星编号， 01 至 32。</li>
<li><code>&lt;5&gt;</code> 卫星仰角， 00 至 90 度。</li>
<li><code>&lt;6&gt;</code> 卫星方位角， 000 至 359 度。实际值。</li>
<li><code>&lt;7&gt;</code> 讯号噪声比（C/No）， 00 至 99
dB；无表未接收到讯号。</li>
<li><code>&lt;8&gt;</code> Checksum（检查位）</li>
</ul>
<p>注意：第 <code>&lt;4&gt;,&lt;5&gt;,&lt;6&gt;,&lt;7&gt;</code>
项个别卫星会重复出现，每行最多有四颗卫星。其余卫星信息会于次一行出现，若未使用，这些字段会空白。</p>
<p>更多关于0183协议详细的介绍，可以查看<a href="https://icofchina.com/d/file/xiazai/2020-09-22/20f1b42b3a11ac52089caf3603b43fb5.pdf">《CASIC多模卫星导航接收机协议规范》</a></p>
<p><strong>在了解了GPS接收机数据的结构后，我们就可以对我们所需要的数据进行筛选并读取了</strong></p>
<h2 id="读入定位信息简单版">读入定位信息(简单版)</h2>
<p>我们先进行本地数据的读取，用GPS接收机接收到数据后，我们先将数据保存在本地，而后进行读取。</p>
<p>要想读取USB串口的数据，我们先要在电脑上安装相应的驱动，CH340转串口芯片支持的平台驱动齐全，支持Windows/Linux/Android/MacOS/WinCE
等各主流系统。下面就给出Windows平台下驱动官网链接和简要说明：</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406102157347.png" alt="image-20230406102157347">
<figcaption aria-hidden="true">image-20230406102157347</figcaption>
</figure>
<p><a href="https://www.wch.cn/download/CH341SER_EXE.html">下载链接</a></p>
<p>下载好后，双击EXE文件运行，弹出安装成功则说明已经完成安装。</p>
<p>将驱动安装完毕后，我们要想接收数据还需要一个软件，下载地址如下：</p>
<p><a href="http://www.daxia.com/download/sscom.rar">下载链接</a></p>
<p>下载好后打开就是一个这样的界面</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406104926222.png" alt="image-20230406104926222">
<figcaption aria-hidden="true">image-20230406104926222</figcaption>
</figure>
<p>该软件是大虾丁丁写的一个串口调试器，在查找串口助手时都推荐使用这个，这个软件是一个免费的，一些关于该软件的问题可以查看<a href="http://www.sscom.vip/">sscom网站</a>，将接收到的数据保存在本地后，就可以在本地读取我们需要的信息了。</p>
<p>读取定位信息，我们需要的定位信息是经纬度，最好加上此次定位的时间，根据之前的介绍，这些数据在GPRMC,GPGGA中都有所体现，我们直接读取即可，python代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_data</span>(<span class="params">file_path</span>):  <span class="comment"># 定义读取数据的函数</span></span><br><span class="line">    IsLineBlank = <span class="number">0</span>  <span class="comment"># 常量，标记读入的行是否为空，为空则说明已经读取完毕，停止继续读入</span></span><br><span class="line"></span><br><span class="line">    Llist = []  <span class="comment"># 存储经度</span></span><br><span class="line">    Blist = []  <span class="comment"># 存储纬度</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">while</span> IsLineBlank != <span class="number">1</span>:  <span class="comment"># 读入的行不为空</span></span><br><span class="line">            line = f.readline()  <span class="comment"># 逐行读入数据</span></span><br><span class="line">            <span class="keyword">if</span> line == <span class="string">&#x27;&#x27;</span>:  <span class="comment"># 判断该行是否为空，是则将IsLineBlank设置为1</span></span><br><span class="line">                IsLineBlank = <span class="number">1</span></span><br><span class="line">            seprated_line = line.split(<span class="string">&#x27;,&#x27;</span>)  <span class="comment"># 0183协议数据之间以,分隔</span></span><br><span class="line">            <span class="keyword">if</span> seprated_line[<span class="number">0</span>] == <span class="string">&#x27;$GPRMC&#x27;</span> <span class="keyword">and</span> seprated_line[<span class="number">2</span>] == <span class="string">&#x27;A&#x27;</span>:  <span class="comment"># 找到数据行，A表示有效定位，方可使用本次数据。</span></span><br><span class="line">                <span class="comment"># 根据0183协议格式找到需要的数据</span></span><br><span class="line">                B = seprated_line[<span class="number">3</span>]  <span class="comment"># 纬度</span></span><br><span class="line">                Btype = seprated_line[<span class="number">4</span>]  <span class="comment"># 纬度的类型，N/S</span></span><br><span class="line">                L = seprated_line[<span class="number">5</span>]  <span class="comment"># 经度</span></span><br><span class="line">                Ltype = seprated_line[<span class="number">6</span>]  <span class="comment"># 经度的类型，W/E</span></span><br><span class="line">                UTCtime = seprated_line[<span class="number">1</span>]  <span class="comment"># UTC时间</span></span><br><span class="line">                UTCdate = seprated_line[<span class="number">9</span>]  <span class="comment"># UTC日期</span></span><br><span class="line">                Llist.append(<span class="built_in">int</span>(L[:<span class="number">3</span>]) + <span class="built_in">float</span>(L[<span class="number">3</span>:]) / <span class="number">60</span>)  <span class="comment"># 存储经度</span></span><br><span class="line">                Blist.append(<span class="built_in">int</span>(B[:<span class="number">2</span>]) + <span class="built_in">float</span>(B[<span class="number">2</span>:]) / <span class="number">60</span>)  <span class="comment"># 存储纬度</span></span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(</span><br><span class="line">                    <span class="string">f&quot;20<span class="subst">&#123;UTCdate[<span class="number">4</span>:]&#125;</span>.<span class="subst">&#123;UTCdate[<span class="number">2</span>:<span class="number">4</span>]&#125;</span>.<span class="subst">&#123;UTCdate[:<span class="number">2</span>]&#125;</span> <span class="subst">&#123;UTCtime[:<span class="number">2</span>]&#125;</span>:<span class="subst">&#123;UTCtime[<span class="number">2</span>:<span class="number">4</span>]&#125;</span>:<span class="subst">&#123;UTCtime[<span class="number">4</span>:]&#125;</span>&quot;</span>)  <span class="comment"># 格式化打印时间</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;B=<span class="subst">&#123;Btype&#125;</span> <span class="subst">&#123;B[:<span class="number">2</span>]&#125;</span>&#x27;<span class="subst">&#123;B[<span class="number">2</span>:]&#125;</span>,L=<span class="subst">&#123;Ltype&#125;</span> <span class="subst">&#123;L[:<span class="number">3</span>]&#125;</span>&#x27;<span class="subst">&#123;L[<span class="number">3</span>:]&#125;</span>&quot;</span>)  <span class="comment"># 格式化打印经纬度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    read_data(<span class="string">&quot;SAVE2023-03-31_10-20-43.DAT&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="读入定位信息进阶版">读入定位信息(进阶版)</h2>
<p>单单只是将数据保存在本地然后读入显然是不够的，那么有没有办法可以边连接串口接受数据边提取出我们需要的数据的，答案是肯定的，不过要用到一些python串口编程的知识。</p>
<h3 id="pyserial串口编程">pySerial串口编程</h3>
<p>pySerial 是 Python 中用于操作串口的第三方模块，它支持
Windows、Linux、OSX、BSD等多个平台。如果要使用 pySerial
模块，首先必须保证 Python 版本高于 Python 2.7 或者 Python
3.4。另外，如果你是用的是 Windows 系统，那必须使用 Win7 及以上的版本。
pySerial 的安装很简单，只需要执行一条命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install pyserial</span><br></pre></td></tr></table></figure>
<p>安装完成后，只需要在 Python 代码中使用 import serial
语句导入该模块即可。</p>
<h4 id="确认端口号">确认端口号</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> serial</span><br><span class="line"><span class="keyword">import</span> serial.tools.list_ports</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取所有串口设备实例。</span></span><br><span class="line"><span class="comment"># 如果没找到串口设备，则输出：“无串口设备。”</span></span><br><span class="line"><span class="comment"># 如果找到串口设备，则依次输出每个设备对应的串口号和描述信息。</span></span><br><span class="line">ports_list = <span class="built_in">list</span>(serial.tools.list_ports.comports())</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(ports_list) &lt;= <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无串口设备。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;可用的串口设备如下：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> comport <span class="keyword">in</span> ports_list:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">list</span>(comport)[<span class="number">0</span>], <span class="built_in">list</span>(comport)[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406224100614.png" alt="image-20230406224100614">
<figcaption aria-hidden="true">image-20230406224100614</figcaption>
</figure>
<p>正是我们GPS接收机的串口</p>
<h4 id="打开串口">打开串口</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ser = serial.Serial(port=<span class="string">&quot;COM5&quot;</span>, baudrate=<span class="number">9600</span>,bytesize=<span class="number">8</span>,stopbits=<span class="number">1</span>)  <span class="comment"># 打开COM5，配置相关参数</span></span><br><span class="line"><span class="keyword">if</span> ser.isOpen():  <span class="comment"># 判断串口是否成功打开</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;打开串口成功。&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(ser.name)  <span class="comment"># 输出串口号</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;打开串口失败。&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在使用 serial.Serial()
创建串口实例时，可以传入的参数很多，常用的参数如下（默认值用<strong>加粗</strong>标记）：</p>
<ul>
<li>port - 串口设备名或 <strong>None</strong>。</li>
<li>baudrate - 波特率，可以是50, 75, 110, 134, 150, 200, 300, 600, 1200,
1800, 2400, 4800, <strong>9600</strong>, 19200, 38400, 57600, 115200,
230400, 460800, 500000, 576000, 921600, 1000000, 1152000, 1500000,
2000000, 2500000, 3000000, 3500000, 4000000。</li>
<li>bytesize - 数据位，可取值为：FIVEBITS, SIXBITS, SEVENBITS,
<strong>EIGHTBITS</strong>。</li>
<li>parity - 校验位，可取值为：<strong>PARITY_NONE</strong>,
PARITY_EVEN, PARITY_ODD, PARITY_MARK, PARITY_SPACE。</li>
<li>stopbits - 停止位，可取值为：<strong>STOPBITS_ONE</strong>,
STOPBITS_ONE_POINT_FIVE, STOPBITS_TOW。</li>
<li>xonxoff - 软件流控，可取值为 True, <strong>False</strong>。</li>
<li>rtscts - 硬件（RTS/CTS）流控，可取值为 True,
<strong>False</strong>。</li>
<li>dsr/dtr - 硬件（DSR/DTR）流控，可取值为 True,
<strong>False</strong>。</li>
<li>timeout - 读超时时间，可取值为 <strong>None</strong>, 0
或者其他具体数值（支持小数）。当设置为 None
时，表示阻塞式读取，一直读到期望的所有数据才返回；当设置为 0
时，表示非阻塞式读取，无论读取到多少数据都立即返回；当设置为其他数值时，表示设置具体的超时时间（以秒为单位），如果在该时间内没有读取到所有数据，则直接返回。</li>
<li>write_timeout: 写超时时间，可取值为 <strong>None</strong>, 0
或者其他具体数值（支持小数）。参数值起到的效果参考 timeout 参数。</li>
</ul>
<p>我们根据sscom界面上的参数配置即可</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406230348646.png" alt="image-20230406230348646">
<figcaption aria-hidden="true">image-20230406230348646</figcaption>
</figure>
<h4 id="读取串口数据">读取串口数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    com_input = ser.read(<span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">if</span> com_input:  <span class="comment"># 如果读取结果非空，则输出</span></span><br><span class="line">        <span class="built_in">print</span>(com_input.decode())</span><br><span class="line"></span><br><span class="line">ser.close()</span><br></pre></td></tr></table></figure>
<p>输出如下</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406230941385.png" alt="image-20230406230941385">
<figcaption aria-hidden="true">image-20230406230941385</figcaption>
</figure>
<p>关于 read() 方法，需要了解如下几点： ① read()
方法默认一次读取一个字节，可以通过传入参数指定每次读取的字节数。 ②
read() 方法会将读取的内容作为返回值，类型为 bytes。 ③
在打开串口时，可以为 read() 方法配置超时时间。</p>
<h4 id="以上就是python串口编程的一些基础操作如果想要了解更多-pyserial-细节可以参考-pyserial官方文档结合上之前的数据读取我们就可以实时的接收数据流并处理了">以上就是python串口编程的一些基础操作，如果想要了解更多
pySerial 细节，可以参考 <a href="https://pyserial.readthedocs.io/en/latest/pyserial.html">pySerial官方文档</a>，结合上之前的数据读取，我们就可以实时的接收数据流并处理了</h4>
<h2 id="将经纬度信息在地图上显示出来基于百度地图api">将经纬度信息在地图上显示出来(基于百度地图API)</h2>
<p>百度地图API是为开发者免费提供的一套基于百度地图服务的应用接口，包括JavaScript
API、Web服务API、Android SDK、iOS
SDK、定位SDK、车联网API、LBS云等多种开发工具与服务，提供基本地图展现、搜索、定位、逆/地理编码、路线规划、LBS云存储与检索等功能，适用于PC端、移动端、服务器等多种设备，多种操作系统下的地图应用开发。</p>
<h3 id="准备工作">准备工作</h3>
<p>在使用百度地图之前，我们需要拥有一个自己的百度账号，并申请注册成为百度开发者，然后我们需要创建一个浏览器端应用，就可以获取到一个唯一的服务秘钥（AK），具体操作如下：</p>
<p>控制台-&gt;应用管理-&gt;我的应用-&gt;创建应用</p>
<p>应用名自取，选择浏览器端，之后点击创建即可。</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406204027293.png" alt="image-20230406204027293">
<figcaption aria-hidden="true">image-20230406204027293</figcaption>
</figure>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406204102705.png" alt="image-20230406204102705">
<figcaption aria-hidden="true">image-20230406204102705</figcaption>
</figure>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406204127169.png" alt="image-20230406204127169">
<figcaption aria-hidden="true">image-20230406204127169</figcaption>
</figure>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406205256087.png" alt="image-20230406205256087">
<figcaption aria-hidden="true">image-20230406205256087</figcaption>
</figure>
<h3 id="静态图">静态图</h3>
<p>百度地图静态图API，可实现将百度地图以图片形式嵌入到您的网页中。您只需发送HTTP请求访问百度地图静态图服务，便可在网页上以图片形式显示您的地图。静态图API较之JavaScript
API载入的动态网站，既能满足基本的地图信息浏览，又能加快网页访问速度。</p>
<p>通过给<strong><code>&lt;img&gt;</code></strong>标签设置src属性即可将地图图片显示在网页中。用户可以指定图片的尺寸、地图的显示范围（包含中心点和缩放级别），还可以放置一些覆盖物在地图上，以生成符合需求的地图图片。</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406211205927.png" alt="image-20230406211205927">
<figcaption aria-hidden="true">image-20230406211205927</figcaption>
</figure>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230406211250221.png" alt="image-20230406211250221">
<figcaption aria-hidden="true">image-20230406211250221</figcaption>
</figure>
<p>让我们来详细阅读一下其服务文档</p>
<h4 id="服务地址">服务地址</h4>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">https:<span class="regexp">//</span>api.map.baidu.com<span class="regexp">/staticimage/</span>v2 <span class="regexp">//</span>GET请求</span><br></pre></td></tr></table></figure>
<p>组成说明：</p>
<ul>
<li>域名：<a href="http://api.map.baidu.com/">https://api.map.baidu.com</a></li>
<li>服务名：staticimage</li>
<li>版本号：v2</li>
</ul>
<p>服务参数列表</p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 4%">
<col style="width: 7%">
<col style="width: 73%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">参数名</th>
<th style="text-align: center;">必选</th>
<th style="text-align: center;">默认值</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">ak</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">无</td>
<td style="text-align: center;">用户的访问密钥。支持浏览器端和服务端ak，网页应用推荐使用
服务端ak(sn校验方式）</td>
</tr>
<tr class="even">
<td style="text-align: center;">mcode</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">无</td>
<td style="text-align: center;">安全码。若为Android/IOS SDK的ak,
该参数必需。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">width</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">400</td>
<td style="text-align: center;">图片宽度。取值范围：(0,
1024]。Scale=2,取值范围：(0, 512]。</td>
</tr>
<tr class="even">
<td style="text-align: center;">height</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">300</td>
<td style="text-align: center;">图片高度。取值范围：(0,
1024]。Scale=2,取值范围：(0, 512]。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">center</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">北京</td>
<td style="text-align: center;">地图中心点位置，参数可以为经纬度坐标或名称。坐标格式：lng<经度>，lat<纬度>，例如116.43213,38.76623。</纬度></经度></td>
</tr>
<tr class="even">
<td style="text-align: center;">zoom</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">地图级别。高清图范围[3,
18]；低清图范围[3,19]</td>
</tr>
<tr class="odd">
<td style="text-align: center;">copyright</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">pl</td>
<td style="text-align: center;">静态图版权样式，0表示log+文字描述样式，1表示纯文字描述样式，默认为0。</td>
</tr>
<tr class="even">
<td style="text-align: center;">dpiType</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">pl</td>
<td style="text-align: center;">手机屏幕类型。取值范围:{ph：高分屏，pl：低分屏(默认)}，高分屏即调用高清地图，低分屏为普通地图。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">coordtype</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">bd09ll</td>
<td style="text-align: center;">静态图的坐标类型。支持wgs84ll（wgs84坐标）/gcj02ll（国测局坐标）/bd09ll（百度经纬度）/bd09mc（百度墨卡托）。默认bd09ll（百度经纬度）</td>
</tr>
<tr class="even">
<td style="text-align: center;">scale</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">返回图片大小会根据此标志调整。取值范围为1或2：
1表示返回的图片大小为size= width * height;
2表示返回图片为(width<em>2)</em>(height <em>2)，且zoom加1
注：如果zoom为最大级别，则返回图片为（width</em>2）<em>（height</em>2），zoom不变。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">bbox</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">地图视野范围。格式：minX,minY;maxX,maxY。</td>
</tr>
<tr class="even">
<td style="text-align: center;">markers</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">标注，可通过经纬度或地址/地名描述；多个标注之间用竖线分隔。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">markerStyles</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">与markers有对应关系。markerStyles可设置默认图标样式和自定义图标样式。其中设置默认图标样式时，可指定的属性包括size,label和color；设置自定义图标时，可指定的属性包括url，注意，设置自定义图标时需要先传-1以此区分默认图标。</td>
</tr>
<tr class="even">
<td style="text-align: center;">labels</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">标签，可通过经纬度或地址/地名描述；多个标签之间用竖线分隔。坐标格式：lng<经度>，lat<纬度>，例如116.43213,38.76623。</纬度></经度></td>
</tr>
<tr class="odd">
<td style="text-align: center;">labelStyles</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">标签样式 content,
fontWeight,fontSize,fontColor,bgColor, border。与labels一一对应。</td>
</tr>
<tr class="even">
<td style="text-align: center;">paths</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">折线，可通过经纬度或地址/地名描述；多个折线用竖线"|"分隔；每条折线的点用分号";"分隔；点坐标用逗号","分隔。坐标格式：lng<经度>，lat<纬度>，例如116.43213,38.76623。</纬度></经度></td>
</tr>
<tr class="odd">
<td style="text-align: center;">pathStyles</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">null</td>
<td style="text-align: center;">折线样式
color,weight,opacity[,fillColor]。</td>
</tr>
</tbody>
</table>
<p>是不是感觉很复杂，没事看个例子就行了：</p>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">https://api.map.baidu.com/staticimage/v2?ak=E4805d16520de693a3fe707cdc962045&amp;center=<span class="number">116.403874</span>,<span class="number">39.914889</span>&amp;width=<span class="number">400</span>&amp;height=<span class="number">300</span>&amp;zoom=<span class="number">11</span>&amp;markers=<span class="number">116.288891</span>,<span class="number">40.004261</span>|<span class="number">116.487812</span>,<span class="number">40.017524</span>|<span class="number">116.525756</span>,<span class="number">39.967111|116</span>.<span class="number">536105,39</span>.<span class="number">872374|116</span>.<span class="number">442968,39</span>.<span class="number">797022|116</span>.<span class="number">270494,39</span>.<span class="number">851993|116</span>.<span class="number">275093,39</span>.<span class="number">935251|116</span>.<span class="number">383177,39</span>.<span class="number">923743</span>&amp;markerStyles=l,<span class="keyword">A</span>|m,B|l,C|l,D|m,E|,|l,G|m,H</span><br><span class="line">// 返回一张在北京地图上添加多个普通标注点的地图图片</span><br></pre></td></tr></table></figure>
<ul>
<li>AK就是你之前创建应用得到的秘钥，可以在我的应用处查看，</li>
<li>center是地图的中心点位置，经纬度之间以逗号分隔，</li>
<li>width&amp;height是地图的宽和高，单位是像素</li>
<li>zoom是地图的级别，百度地图 API 中共有 19 个级别</li>
</ul>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/e0951c20e1f84f52b8839ddfd76c9445.png#pic_center" alt="在这里插入图片描述">
<figcaption aria-hidden="true">在这里插入图片描述</figcaption>
</figure>
<p>​ <strong>注意：</strong> ​ <strong>1、在项目中使用百度地图时，层级为 3
时，世界地图大小已经和容器的大小一致；</strong> ​ <strong>2、级别 为 2
时，地图的大小是容器的一半；</strong> ​ <strong>3、地图显示级别为 1
时，地图的长宽大约为
容器的四分之一，而且在使用时，特别不好找到地图；</strong> ​
<strong>因此，我们在项目中使用百度地图时，一定要使用合适的地图层级。</strong></p>
<ul>
<li>markers就是你要标记的点的经纬度，多组经纬度之间以|分隔</li>
<li>markerStyles与markers有对应关系。markerStyles可设置默认图标样式和自定义图标样式。这里我们就用它给的实例中的样式就行了。</li>
</ul>
<p>那么我们该怎么得到这个复杂的url呢？归根结底这个url就是在https://api.map.baidu.com/staticimage/v2这个服务地址的基础上添加了一些参数，有一些网络或者爬虫的知识就能很快的完成这个复杂的url的构造，不过这个url中还出现了？，&amp;以外的符号，所以并不能直接构造，建议还是用字符串拼接而成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ak = <span class="string">&quot;c2h0qrckzqLUIwLtcnc80OOTBgGrbpiV&quot;</span></span><br><span class="line">width = <span class="number">400</span></span><br><span class="line">height = <span class="number">300</span></span><br><span class="line">zoom = <span class="number">19</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">f&quot;https://api.map.baidu.com/staticimage/v2?ak=<span class="subst">&#123;ak&#125;</span>&amp;center=<span class="subst">&#123;Llist[<span class="number">0</span>]&#125;</span>,<span class="subst">&#123;Blist[<span class="number">0</span>]&#125;</span>&amp;width=400&amp;height=300&amp;zoom=19&amp;markers=&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Blist)):</span><br><span class="line">    url = url + <span class="string">f&quot;<span class="subst">&#123;Llist[i]&#125;</span>,<span class="subst">&#123;Blist[i]&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">if</span> i != <span class="built_in">len</span>(Blist) - <span class="number">1</span>:</span><br><span class="line">        url = url + <span class="string">&quot;|&quot;</span></span><br><span class="line">url = url + <span class="string">&quot;&amp;markerStyles=l,A|m,B|l,C|l,D|m,E|,|l,G|m,H&quot;</span></span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230407112901379.png" alt="image-20230407112901379">
<figcaption aria-hidden="true">image-20230407112901379</figcaption>
</figure>
<p>我们点击这个链接打开看一下是否能得到我们想要的地图</p>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230407112938430.png" alt="image-20230407112938430">
<figcaption aria-hidden="true">image-20230407112938430</figcaption>
</figure>
<p>发现确实是成功了。那么我们想要将图片保存在本地，只需要用一些基础的爬虫知识就可以完成了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;map.jpg&quot;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    f.write(resp.content)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2023/04/04/%E4%B8%80%E6%96%87%E6%90%9E%E5%AE%9A%E5%AF%BC%E8%88%AA%E6%8E%A5%E6%94%B6%E6%9C%BA%E5%AE%9A%E4%BD%8D/image-20230407113124833.png" alt="image-20230407113124833">
<figcaption aria-hidden="true">image-20230407113124833</figcaption>
</figure>
<p><strong>搞定！！</strong></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>技术</tag>
        <tag>GPS</tag>
        <tag>接收机</tag>
      </tags>
  </entry>
</search>
